{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get test data from checklist test\n",
    "Base code retrieved from: https://github.com/sophiamyang/NLP_testing/blob/main/SQuAD-get-checklist-data.ipynb\n",
    "\n",
    "This file is copied from `1. SQuAD-create-test-suite.ipynb`. I removed the irrelavant cells. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline \n",
    "\n",
    "model = pipeline('question-answering', model=\"distilbert-base-cased-distilled-squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import checklist\n",
    "import itertools\n",
    "\n",
    "import checklist.editor\n",
    "import checklist.text_generation\n",
    "from checklist.expect import Expect\n",
    "import numpy as np\n",
    "from checklist.perturb import Perturb\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset squad (C:/Users/fgmal/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708a52f7052d4097818aa36e54a1f6c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\fgmal\\.cache\\huggingface\\datasets\\squad\\plain_text\\1.0.0\\d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453\\cache-6882b6599f6aef9b.arrow\n",
      "Loading cached processed dataset at C:\\Users\\fgmal\\.cache\\huggingface\\datasets\\squad\\plain_text\\1.0.0\\d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453\\cache-ccb8f8f6fcce10c6.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b4e3e5a5a140d4907dc425493a7b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/88 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>{\"text\": [\"Saint Bernadette Soubirous\"], \"answ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5733be284776f4190066117f</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is in front of the Notre Dame Main Building?</td>\n",
       "      <td>{\"text\": [\"a copper statue of Christ\"], \"answe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5733be284776f41900661180</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
       "      <td>{\"text\": [\"the Main Building\"], \"answer_start\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5733be284776f41900661181</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What is the Grotto at Notre Dame?</td>\n",
       "      <td>{\"text\": [\"a Marian place of prayer and reflec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5733be284776f4190066117e</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>What sits on top of the Main Building at Notre...</td>\n",
       "      <td>{\"text\": [\"a golden statue of the Virgin Mary\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87594</th>\n",
       "      <td>5735d259012e2f140011a09d</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>In what US state did Kathmandu first establish...</td>\n",
       "      <td>{\"text\": [\"Oregon\"], \"answer_start\": [229]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87595</th>\n",
       "      <td>5735d259012e2f140011a09e</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>What was Yangon previously known as?</td>\n",
       "      <td>{\"text\": [\"Rangoon\"], \"answer_start\": [414]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87596</th>\n",
       "      <td>5735d259012e2f140011a09f</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>With what Belorussian city does Kathmandu have...</td>\n",
       "      <td>{\"text\": [\"Minsk\"], \"answer_start\": [476]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87597</th>\n",
       "      <td>5735d259012e2f140011a0a0</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>In what year did Kathmandu create its initial ...</td>\n",
       "      <td>{\"text\": [\"1975\"], \"answer_start\": [199]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87598</th>\n",
       "      <td>5735d259012e2f140011a0a1</td>\n",
       "      <td>Kathmandu</td>\n",
       "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
       "      <td>What is KMC an initialism of?</td>\n",
       "      <td>{\"text\": [\"Kathmandu Metropolitan City\"], \"ans...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87599 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             id                     title  \\\n",
       "0      5733be284776f41900661182  University_of_Notre_Dame   \n",
       "1      5733be284776f4190066117f  University_of_Notre_Dame   \n",
       "2      5733be284776f41900661180  University_of_Notre_Dame   \n",
       "3      5733be284776f41900661181  University_of_Notre_Dame   \n",
       "4      5733be284776f4190066117e  University_of_Notre_Dame   \n",
       "...                         ...                       ...   \n",
       "87594  5735d259012e2f140011a09d                 Kathmandu   \n",
       "87595  5735d259012e2f140011a09e                 Kathmandu   \n",
       "87596  5735d259012e2f140011a09f                 Kathmandu   \n",
       "87597  5735d259012e2f140011a0a0                 Kathmandu   \n",
       "87598  5735d259012e2f140011a0a1                 Kathmandu   \n",
       "\n",
       "                                                 context  \\\n",
       "0      Architecturally, the school has a Catholic cha...   \n",
       "1      Architecturally, the school has a Catholic cha...   \n",
       "2      Architecturally, the school has a Catholic cha...   \n",
       "3      Architecturally, the school has a Catholic cha...   \n",
       "4      Architecturally, the school has a Catholic cha...   \n",
       "...                                                  ...   \n",
       "87594  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87595  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87596  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87597  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "87598  Kathmandu Metropolitan City (KMC), in order to...   \n",
       "\n",
       "                                                question  \\\n",
       "0      To whom did the Virgin Mary allegedly appear i...   \n",
       "1      What is in front of the Notre Dame Main Building?   \n",
       "2      The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                      What is the Grotto at Notre Dame?   \n",
       "4      What sits on top of the Main Building at Notre...   \n",
       "...                                                  ...   \n",
       "87594  In what US state did Kathmandu first establish...   \n",
       "87595               What was Yangon previously known as?   \n",
       "87596  With what Belorussian city does Kathmandu have...   \n",
       "87597  In what year did Kathmandu create its initial ...   \n",
       "87598                      What is KMC an initialism of?   \n",
       "\n",
       "                                                 answers  \n",
       "0      {\"text\": [\"Saint Bernadette Soubirous\"], \"answ...  \n",
       "1      {\"text\": [\"a copper statue of Christ\"], \"answe...  \n",
       "2      {\"text\": [\"the Main Building\"], \"answer_start\"...  \n",
       "3      {\"text\": [\"a Marian place of prayer and reflec...  \n",
       "4      {\"text\": [\"a golden statue of the Virgin Mary\"...  \n",
       "...                                                  ...  \n",
       "87594        {\"text\": [\"Oregon\"], \"answer_start\": [229]}  \n",
       "87595       {\"text\": [\"Rangoon\"], \"answer_start\": [414]}  \n",
       "87596         {\"text\": [\"Minsk\"], \"answer_start\": [476]}  \n",
       "87597          {\"text\": [\"1975\"], \"answer_start\": [199]}  \n",
       "87598  {\"text\": [\"Kathmandu Metropolitan City\"], \"ans...  \n",
       "\n",
       "[87599 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SAVE SQUAD DATASET TO CSV \n",
    "\n",
    "dataset = datasets.load_dataset('squad')\n",
    "def format_dataset(example):\n",
    "    \"\"\"\n",
    "    format answers from dict to json\n",
    "    so that data looks consistent when exporting to csv\n",
    "    \"\"\"\n",
    "    example['answers'] = json.dumps(example['answers'])\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(format_dataset)\n",
    "dataset['train'].to_csv('train.csv', index=None)\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def dataset_fmt(t, file_name):\n",
    "    \"\"\"\n",
    "    format t to acceptable dataframe format \n",
    "    \"\"\"\n",
    "    df = pd.DataFrame([\n",
    "        {'context':i[k][0], 'question':i[k][1], 'answers_text': j[k]}\n",
    "        for i, j in zip(t.data, t.labels)\n",
    "        for k in range(len(i))\n",
    "    ])\n",
    "    df['answer_start'] = df.apply(lambda row: row['context'].index(row['answers_text']), axis=1)\n",
    "    df['answers'] = df.apply(lambda row: {'text': [row['answers_text']], 'answer_start': [row['answer_start']]}, axis=1)\n",
    "    df = df.drop(columns=['answers_text', 'answer_start'])\n",
    "    df['answers'] = df['answers'].apply(json.dumps)\n",
    "    df = df.drop_duplicates().reset_index(drop=True)\n",
    "    df.to_csv(f'new_data/{file_name}.csv', index=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def inv_dataset_fmt(t, file_name, df_train=df_train):\n",
    "    \"\"\"\n",
    "    use original answers for invariance cases\n",
    "    note that in many cases start position changes, that's why we find the correct index \n",
    "    \"\"\"\n",
    "    df = pd.DataFrame([{'context':i[0][0], 'question':i[0][1], 'context_modified':i[1][0], 'question_modified':i[1][1]} for i in t.data])\n",
    "    df = (\n",
    "        df\n",
    "        .merge(df_train, on=['context','question'], how='inner')\n",
    "        .drop(columns=['context', 'question', 'id', 'title'])\n",
    "        .rename(columns={'context_modified': 'context', 'question_modified':'question'})\n",
    "        .drop_duplicates(subset=['context','question'])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    # df = find_matching_index(df)\n",
    "    df['answers'] = df['answers'].apply(json.dumps)\n",
    "    df.to_csv(f'new_data/{file_name}.csv', index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def find_all_matching(string, sentence):\n",
    "    matching_lst = []\n",
    "    for m in re.finditer(re.escape(string), sentence): #re.escape deals with weird character issues\n",
    "        matching_lst.append(m.start())\n",
    "    return matching_lst\n",
    "\n",
    "def find_matching_index(df):\n",
    "    for index, row in df.iterrows(): \n",
    "        row['answers'] = json.loads(row['answers'])\n",
    "        for i in range(len(row['answers']['text'])):\n",
    "            original_index = row['answers']['answer_start'][i]\n",
    "            all_matched_indexes = find_all_matching(row['answers']['text'][i], row['context'])\n",
    "            if len(all_matched_indexes) ==0:\n",
    "                pass\n",
    "            elif original_index in all_matched_indexes:\n",
    "                # if the original index is in the matched indexes, do nothing\n",
    "                pass\n",
    "            else:\n",
    "                print(index)\n",
    "                print(row)\n",
    "                print('changed')\n",
    "                # if not, choose the index that's the closest to the original index\n",
    "                row['answers']['answer_start'][i] = min(all_matched_indexes, key=lambda x: abs(x - original_index))\n",
    "                print(original_index)\n",
    "                print(row['answers']['answer_start'][i])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<checklist.text_generation.TextGenerator at 0x1e711234520>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editor = checklist.editor.Editor()\n",
    "editor.tg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = ['old', 'smart', 'tall', 'young', 'strong', 'short', 'tough', 'cool', 'fast', 'nice', 'small', 'dark', 'wise', 'rich', 'great', 'weak', 'high', 'slow', 'strange', 'clean']\n",
    "adj = [(x.rstrip('e'), x) for x in adj]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = editor.template(\n",
    "    [(\n",
    "    '{first_name} is {adj[0]}er than {first_name1}.',\n",
    "    'Who is {adj[0]}er?'\n",
    "    )\n",
    "    ],\n",
    "    labels = ['{first_name}'],\n",
    "    adj=adj,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    )\n",
    "name = 'A is COMP than B. Who is more COMP?'\n",
    "# description = ''\n",
    "# test = MFT(**t, name=name, description=description, capability='Vocabulary')\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amanda is cleaner than Jim.</td>\n",
       "      <td>Who is cleaner?</td>\n",
       "      <td>{\"text\": [\"Amanda\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lucy is richer than Anthony.</td>\n",
       "      <td>Who is richer?</td>\n",
       "      <td>{\"text\": [\"Lucy\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patricia is smarter than Donald.</td>\n",
       "      <td>Who is smarter?</td>\n",
       "      <td>{\"text\": [\"Patricia\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jessica is stronger than Francis.</td>\n",
       "      <td>Who is stronger?</td>\n",
       "      <td>{\"text\": [\"Jessica\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bob is cooler than Eleanor.</td>\n",
       "      <td>Who is cooler?</td>\n",
       "      <td>{\"text\": [\"Bob\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>Bobby is cleaner than Arthur.</td>\n",
       "      <td>Who is cleaner?</td>\n",
       "      <td>{\"text\": [\"Bobby\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>Michael is wiser than Joseph.</td>\n",
       "      <td>Who is wiser?</td>\n",
       "      <td>{\"text\": [\"Michael\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Grace is stronger than Dick.</td>\n",
       "      <td>Who is stronger?</td>\n",
       "      <td>{\"text\": [\"Grace\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Claire is richer than Caroline.</td>\n",
       "      <td>Who is richer?</td>\n",
       "      <td>{\"text\": [\"Claire\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Kenneth is faster than Anna.</td>\n",
       "      <td>Who is faster?</td>\n",
       "      <td>{\"text\": [\"Kenneth\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               context          question  \\\n",
       "0          Amanda is cleaner than Jim.   Who is cleaner?   \n",
       "1         Lucy is richer than Anthony.    Who is richer?   \n",
       "2     Patricia is smarter than Donald.   Who is smarter?   \n",
       "3    Jessica is stronger than Francis.  Who is stronger?   \n",
       "4          Bob is cooler than Eleanor.    Who is cooler?   \n",
       "..                                 ...               ...   \n",
       "493      Bobby is cleaner than Arthur.   Who is cleaner?   \n",
       "494      Michael is wiser than Joseph.     Who is wiser?   \n",
       "495       Grace is stronger than Dick.  Who is stronger?   \n",
       "496    Claire is richer than Caroline.    Who is richer?   \n",
       "497       Kenneth is faster than Anna.    Who is faster?   \n",
       "\n",
       "                                         answers  \n",
       "0      {\"text\": [\"Amanda\"], \"answer_start\": [0]}  \n",
       "1        {\"text\": [\"Lucy\"], \"answer_start\": [0]}  \n",
       "2    {\"text\": [\"Patricia\"], \"answer_start\": [0]}  \n",
       "3     {\"text\": [\"Jessica\"], \"answer_start\": [0]}  \n",
       "4         {\"text\": [\"Bob\"], \"answer_start\": [0]}  \n",
       "..                                           ...  \n",
       "493     {\"text\": [\"Bobby\"], \"answer_start\": [0]}  \n",
       "494   {\"text\": [\"Michael\"], \"answer_start\": [0]}  \n",
       "495     {\"text\": [\"Grace\"], \"answer_start\": [0]}  \n",
       "496    {\"text\": [\"Claire\"], \"answer_start\": [0]}  \n",
       "497   {\"text\": [\"Kenneth\"], \"answer_start\": [0]}  \n",
       "\n",
       "[498 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"compare_more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = editor.template(\n",
    "    [(\n",
    "    '{first_name} is {adj[0]}er than {first_name1}.',\n",
    "    'Who is less {adj[1]}?'\n",
    "    )\n",
    "    ],\n",
    "    labels = ['{first_name1}'],\n",
    "    adj=adj,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    )\n",
    "name = 'A is COMP than B. Who is less COMP?'\n",
    "# description = ''\n",
    "# test = MFT(**t, name=name, description=description, capability='Vocabulary')\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joseph is older than George.</td>\n",
       "      <td>Who is less old?</td>\n",
       "      <td>{\"text\": [\"George\"], \"answer_start\": [21]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Frances is smaller than Evelyn.</td>\n",
       "      <td>Who is less small?</td>\n",
       "      <td>{\"text\": [\"Evelyn\"], \"answer_start\": [24]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ashley is wiser than Donna.</td>\n",
       "      <td>Who is less wise?</td>\n",
       "      <td>{\"text\": [\"Donna\"], \"answer_start\": [21]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Larry is shorter than Caroline.</td>\n",
       "      <td>Who is less short?</td>\n",
       "      <td>{\"text\": [\"Caroline\"], \"answer_start\": [22]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thomas is darker than Jimmy.</td>\n",
       "      <td>Who is less dark?</td>\n",
       "      <td>{\"text\": [\"Jimmy\"], \"answer_start\": [22]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>Sam is greater than Charles.</td>\n",
       "      <td>Who is less great?</td>\n",
       "      <td>{\"text\": [\"Charles\"], \"answer_start\": [20]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>Francis is higher than Julia.</td>\n",
       "      <td>Who is less high?</td>\n",
       "      <td>{\"text\": [\"Julia\"], \"answer_start\": [23]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>Matthew is weaker than Nicole.</td>\n",
       "      <td>Who is less weak?</td>\n",
       "      <td>{\"text\": [\"Nicole\"], \"answer_start\": [23]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>Don is cleaner than Kevin.</td>\n",
       "      <td>Who is less clean?</td>\n",
       "      <td>{\"text\": [\"Kevin\"], \"answer_start\": [20]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>Victoria is stronger than Samuel.</td>\n",
       "      <td>Who is less strong?</td>\n",
       "      <td>{\"text\": [\"Samuel\"], \"answer_start\": [26]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>494 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               context             question  \\\n",
       "0         Joseph is older than George.     Who is less old?   \n",
       "1      Frances is smaller than Evelyn.   Who is less small?   \n",
       "2          Ashley is wiser than Donna.    Who is less wise?   \n",
       "3      Larry is shorter than Caroline.   Who is less short?   \n",
       "4         Thomas is darker than Jimmy.    Who is less dark?   \n",
       "..                                 ...                  ...   \n",
       "489       Sam is greater than Charles.   Who is less great?   \n",
       "490      Francis is higher than Julia.    Who is less high?   \n",
       "491     Matthew is weaker than Nicole.    Who is less weak?   \n",
       "492         Don is cleaner than Kevin.   Who is less clean?   \n",
       "493  Victoria is stronger than Samuel.  Who is less strong?   \n",
       "\n",
       "                                          answers  \n",
       "0      {\"text\": [\"George\"], \"answer_start\": [21]}  \n",
       "1      {\"text\": [\"Evelyn\"], \"answer_start\": [24]}  \n",
       "2       {\"text\": [\"Donna\"], \"answer_start\": [21]}  \n",
       "3    {\"text\": [\"Caroline\"], \"answer_start\": [22]}  \n",
       "4       {\"text\": [\"Jimmy\"], \"answer_start\": [22]}  \n",
       "..                                            ...  \n",
       "489   {\"text\": [\"Charles\"], \"answer_start\": [20]}  \n",
       "490     {\"text\": [\"Julia\"], \"answer_start\": [23]}  \n",
       "491    {\"text\": [\"Nicole\"], \"answer_start\": [23]}  \n",
       "492     {\"text\": [\"Kevin\"], \"answer_start\": [20]}  \n",
       "493    {\"text\": [\"Samuel\"], \"answer_start\": [26]}  \n",
       "\n",
       "[494 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"compare_less\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossproduct(t):\n",
    "    # takes the output of editor.template and does the cross product of contexts and qas\n",
    "    ret = []\n",
    "    ret_labels = []\n",
    "    for x in t.data:\n",
    "        cs = x['contexts']\n",
    "        qas = x['qas']\n",
    "        d = list(itertools.product(cs, qas))\n",
    "        ret.append([(x[0], x[1][0]) for x in d])\n",
    "        ret_labels.append([x[1][1] for x in d])\n",
    "    t.data = ret\n",
    "    t.labels = ret_labels\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very, pretty, extremely, also, still, quite, more, really, not, clearly, fairly, incredibly, particularly, now, understandably, rather, cautiously, surprisingly, certainly, feeling, so, especially, definitely, generally, most, highly, super, reportedly, being, obviously\n"
     ]
    }
   ],
   "source": [
    "state = editor.suggest('John is very {mask} about the project.')[:20]\n",
    "print(', '.join(editor.suggest('John is {mask} {state} about the project.', state=state)[:30]))\n",
    "very = ['very', 'extremely', 'really', 'quite', 'incredibly', 'particularly', 'highly', 'super']\n",
    "somewhat = ['a little', 'somewhat', 'slightly', 'mildly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is {very} {s} about the project. {first_name1} is {s} about the project.',\n",
    "            '{first_name1} is {s} about the project. {first_name} is {very} {s} about the project.',\n",
    "            '{first_name} is {s} about the project. {first_name1} is {somewhat} {s} about the project.',\n",
    "            '{first_name1} is {somewhat} {s} about the project. {first_name} is {s} about the project.',\n",
    "            '{first_name} is {very} {s} about the project. {first_name1} is {somewhat} {s} about the project.',\n",
    "            '{first_name1} is {somewhat} {s} about the project. {first_name} is {very} {s} about the project.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is most {s} about the project?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is least {s} about the project?',\n",
    "                '{first_name1}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    s = state,\n",
    "    very=very,\n",
    "    somewhat=somewhat,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))\n",
    "name = 'Intensifiers (very, super, extremely) and reducers (somewhat, kinda, etc)?'\n",
    "# desc = ''\n",
    "# test = MFT(**t, name=name, description=desc, capability='Vocabulary')\n",
    "# suite.add(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ken is incredibly curious about the project. D...</td>\n",
       "      <td>Who is most curious about the project?</td>\n",
       "      <td>{\"text\": [\"Ken\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ken is incredibly curious about the project. D...</td>\n",
       "      <td>Who is least curious about the project?</td>\n",
       "      <td>{\"text\": [\"Diana\"], \"answer_start\": [45]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Diana is curious about the project. Ken is inc...</td>\n",
       "      <td>Who is most curious about the project?</td>\n",
       "      <td>{\"text\": [\"Ken\"], \"answer_start\": [36]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diana is curious about the project. Ken is inc...</td>\n",
       "      <td>Who is least curious about the project?</td>\n",
       "      <td>{\"text\": [\"Diana\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ken is curious about the project. Diana is sli...</td>\n",
       "      <td>Who is most curious about the project?</td>\n",
       "      <td>{\"text\": [\"Ken\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5959</th>\n",
       "      <td>Pamela is mildly hopeful about the project. Ad...</td>\n",
       "      <td>Who is least hopeful about the project?</td>\n",
       "      <td>{\"text\": [\"Pamela\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5960</th>\n",
       "      <td>Adam is super hopeful about the project. Pamel...</td>\n",
       "      <td>Who is most hopeful about the project?</td>\n",
       "      <td>{\"text\": [\"Adam\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5961</th>\n",
       "      <td>Adam is super hopeful about the project. Pamel...</td>\n",
       "      <td>Who is least hopeful about the project?</td>\n",
       "      <td>{\"text\": [\"Pamela\"], \"answer_start\": [41]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5962</th>\n",
       "      <td>Pamela is mildly hopeful about the project. Ad...</td>\n",
       "      <td>Who is most hopeful about the project?</td>\n",
       "      <td>{\"text\": [\"Adam\"], \"answer_start\": [44]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5963</th>\n",
       "      <td>Pamela is mildly hopeful about the project. Ad...</td>\n",
       "      <td>Who is least hopeful about the project?</td>\n",
       "      <td>{\"text\": [\"Pamela\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5964 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                context  \\\n",
       "0     Ken is incredibly curious about the project. D...   \n",
       "1     Ken is incredibly curious about the project. D...   \n",
       "2     Diana is curious about the project. Ken is inc...   \n",
       "3     Diana is curious about the project. Ken is inc...   \n",
       "4     Ken is curious about the project. Diana is sli...   \n",
       "...                                                 ...   \n",
       "5959  Pamela is mildly hopeful about the project. Ad...   \n",
       "5960  Adam is super hopeful about the project. Pamel...   \n",
       "5961  Adam is super hopeful about the project. Pamel...   \n",
       "5962  Pamela is mildly hopeful about the project. Ad...   \n",
       "5963  Pamela is mildly hopeful about the project. Ad...   \n",
       "\n",
       "                                     question  \\\n",
       "0      Who is most curious about the project?   \n",
       "1     Who is least curious about the project?   \n",
       "2      Who is most curious about the project?   \n",
       "3     Who is least curious about the project?   \n",
       "4      Who is most curious about the project?   \n",
       "...                                       ...   \n",
       "5959  Who is least hopeful about the project?   \n",
       "5960   Who is most hopeful about the project?   \n",
       "5961  Who is least hopeful about the project?   \n",
       "5962   Who is most hopeful about the project?   \n",
       "5963  Who is least hopeful about the project?   \n",
       "\n",
       "                                         answers  \n",
       "0         {\"text\": [\"Ken\"], \"answer_start\": [0]}  \n",
       "1      {\"text\": [\"Diana\"], \"answer_start\": [45]}  \n",
       "2        {\"text\": [\"Ken\"], \"answer_start\": [36]}  \n",
       "3       {\"text\": [\"Diana\"], \"answer_start\": [0]}  \n",
       "4         {\"text\": [\"Ken\"], \"answer_start\": [0]}  \n",
       "...                                          ...  \n",
       "5959   {\"text\": [\"Pamela\"], \"answer_start\": [0]}  \n",
       "5960     {\"text\": [\"Adam\"], \"answer_start\": [0]}  \n",
       "5961  {\"text\": [\"Pamela\"], \"answer_start\": [41]}  \n",
       "5962    {\"text\": [\"Adam\"], \"answer_start\": [44]}  \n",
       "5963   {\"text\": [\"Pamela\"], \"answer_start\": [0]}  \n",
       "\n",
       "[5964 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"intensifiers_reducers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxonomy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size, chape, color, age, material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import munch\n",
    "order = ['size', 'shape', 'age', 'color']\n",
    "props = []\n",
    "properties = {\n",
    "    'color' : ['red', 'blue','yellow', 'green', 'pink', 'white', 'black', 'orange', 'grey', 'purple', 'brown'],\n",
    "    'size' : ['big', 'small', 'tiny', 'enormous'],\n",
    "    'age' : ['old', 'new'],\n",
    "    'shape' : ['round', 'oval', 'square', 'triangular'],\n",
    "    'material' : ['iron', 'wooden', 'ceramic', 'glass', 'stone']\n",
    "}\n",
    "for i in range(len(order)):\n",
    "    for j in range(i + 1, len(order)):\n",
    "        p1, p2 = order[i], order[j]\n",
    "        for v1, v2 in itertools.product(properties[p1], properties[p2]):\n",
    "            props.append(munch.Munch({\n",
    "                'p1': p1,\n",
    "                'p2': p2,\n",
    "                'v1': v1,\n",
    "                'v2': v2,\n",
    "            }))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sofa, couch, wall, carpet, chair, table, light, lamp, door, clock, mirror, desk, bed, TV, bar, television, window, box, tree, painting, curtain, fan, fridge, screen, wallpaper, piano, rug, shelf, camera, candle\n"
     ]
    }
   ],
   "source": [
    "print(', '.join(editor.suggest('There is {a:p.v1} {p.v2} {mask} in the room.', p=props, verbose=False)[:30]))\n",
    "objects = ['box', 'clock', 'table', 'object', 'toy', 'painting', 'sculpture', 'thing', 'figure']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            'There is {a:p.v1} {p.v2} {obj} in the room.',\n",
    "            'There is {a:obj} in the room. The {obj} is {p.v1} and {p.v2}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'What {p.p1} is the {obj}?',\n",
    "                '{p.v1}'\n",
    "            ), \n",
    "            (\n",
    "                'What {p.p2} is the {obj}?',\n",
    "                '{p.v2}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    obj=objects,\n",
    "    p=props,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))\n",
    "name = 'size, shape, age, color'\n",
    "desc = ''\n",
    "# test = MFT(**t, name=name, description=desc, capability='Taxonomy')\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There is an oval brown table in the room.</td>\n",
       "      <td>What shape is the table?</td>\n",
       "      <td>{\"text\": [\"oval\"], \"answer_start\": [12]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There is an oval brown table in the room.</td>\n",
       "      <td>What color is the table?</td>\n",
       "      <td>{\"text\": [\"brown\"], \"answer_start\": [17]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There is a table in the room. The table is ova...</td>\n",
       "      <td>What shape is the table?</td>\n",
       "      <td>{\"text\": [\"oval\"], \"answer_start\": [43]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>There is a table in the room. The table is ova...</td>\n",
       "      <td>What color is the table?</td>\n",
       "      <td>{\"text\": [\"brown\"], \"answer_start\": [52]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There is a big oval toy in the room.</td>\n",
       "      <td>What size is the toy?</td>\n",
       "      <td>{\"text\": [\"big\"], \"answer_start\": [11]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>There is a box in the room. The box is enormou...</td>\n",
       "      <td>What color is the box?</td>\n",
       "      <td>{\"text\": [\"blue\"], \"answer_start\": [52]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>There is an enormous black thing in the room.</td>\n",
       "      <td>What size is the thing?</td>\n",
       "      <td>{\"text\": [\"enormous\"], \"answer_start\": [12]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>There is an enormous black thing in the room.</td>\n",
       "      <td>What color is the thing?</td>\n",
       "      <td>{\"text\": [\"black\"], \"answer_start\": [21]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>There is a thing in the room. The thing is eno...</td>\n",
       "      <td>What size is the thing?</td>\n",
       "      <td>{\"text\": [\"enormous\"], \"answer_start\": [43]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>There is a thing in the room. The thing is eno...</td>\n",
       "      <td>What color is the thing?</td>\n",
       "      <td>{\"text\": [\"black\"], \"answer_start\": [56]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1640 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                context  \\\n",
       "0             There is an oval brown table in the room.   \n",
       "1             There is an oval brown table in the room.   \n",
       "2     There is a table in the room. The table is ova...   \n",
       "3     There is a table in the room. The table is ova...   \n",
       "4                  There is a big oval toy in the room.   \n",
       "...                                                 ...   \n",
       "1635  There is a box in the room. The box is enormou...   \n",
       "1636      There is an enormous black thing in the room.   \n",
       "1637      There is an enormous black thing in the room.   \n",
       "1638  There is a thing in the room. The thing is eno...   \n",
       "1639  There is a thing in the room. The thing is eno...   \n",
       "\n",
       "                      question                                       answers  \n",
       "0     What shape is the table?      {\"text\": [\"oval\"], \"answer_start\": [12]}  \n",
       "1     What color is the table?     {\"text\": [\"brown\"], \"answer_start\": [17]}  \n",
       "2     What shape is the table?      {\"text\": [\"oval\"], \"answer_start\": [43]}  \n",
       "3     What color is the table?     {\"text\": [\"brown\"], \"answer_start\": [52]}  \n",
       "4        What size is the toy?       {\"text\": [\"big\"], \"answer_start\": [11]}  \n",
       "...                        ...                                           ...  \n",
       "1635    What color is the box?      {\"text\": [\"blue\"], \"answer_start\": [52]}  \n",
       "1636   What size is the thing?  {\"text\": [\"enormous\"], \"answer_start\": [12]}  \n",
       "1637  What color is the thing?     {\"text\": [\"black\"], \"answer_start\": [21]}  \n",
       "1638   What size is the thing?  {\"text\": [\"enormous\"], \"answer_start\": [43]}  \n",
       "1639  What color is the thing?     {\"text\": [\"black\"], \"answer_start\": [56]}  \n",
       "\n",
       "[1640 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"size_shape_age_color\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Professions vs nationalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "professions = editor.suggest('{first_name} works as {a:mask}.')[:30]\n",
    "professions += editor.suggest('{first_name} {last_name} works as {a:mask}.')[:30]\n",
    "professions = list(set(professions))\n",
    "if 'translator' in professions:\n",
    "    professions.remove('translator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(string):\n",
    "    return string.lstrip('[a,the,an,in,at] ').rstrip('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expect_squad(x, pred, conf, label=None, meta=None):\n",
    "    return clean(pred) == clean(label)\n",
    "expect_squad = Expect.single(expect_squad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is {a:nat} {prof}.',\n",
    "            '{first_name} is {a:prof}. {first_name} is {nat}.',\n",
    "            '{first_name} is {nat}. {first_name} is {a:prof}.',\n",
    "            '{first_name} is {nat} and {a:prof}.',\n",
    "            '{first_name} is {a:prof} and {nat}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'What is {first_name}\\'s job?',\n",
    "                '{prof}'\n",
    "            ), \n",
    "            (\n",
    "                'What is {first_name}\\'s nationality?',\n",
    "                '{nat}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    nat = editor.lexicons['nationality'][:10],\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True,\n",
    "    ))\n",
    "name = 'Profession vs nationality'\n",
    "# test = MFT(**t, name=name, expect=expect_squad, description='',  capability='Taxonomy')\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Catherine is a Bangladeshi waitress.</td>\n",
       "      <td>What is Catherine's job?</td>\n",
       "      <td>{\"text\": [\"waitress\"], \"answer_start\": [27]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Catherine is a Bangladeshi waitress.</td>\n",
       "      <td>What is Catherine's nationality?</td>\n",
       "      <td>{\"text\": [\"Bangladeshi\"], \"answer_start\": [15]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Catherine is a waitress. Catherine is Banglade...</td>\n",
       "      <td>What is Catherine's job?</td>\n",
       "      <td>{\"text\": [\"waitress\"], \"answer_start\": [15]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Catherine is a waitress. Catherine is Banglade...</td>\n",
       "      <td>What is Catherine's nationality?</td>\n",
       "      <td>{\"text\": [\"Bangladeshi\"], \"answer_start\": [38]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Catherine is Bangladeshi. Catherine is a waitr...</td>\n",
       "      <td>What is Catherine's job?</td>\n",
       "      <td>{\"text\": [\"waitress\"], \"answer_start\": [41]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4985</th>\n",
       "      <td>Martha is Pakistani. Martha is an engineer.</td>\n",
       "      <td>What is Martha's nationality?</td>\n",
       "      <td>{\"text\": [\"Pakistani\"], \"answer_start\": [10]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>Martha is Pakistani and an engineer.</td>\n",
       "      <td>What is Martha's job?</td>\n",
       "      <td>{\"text\": [\"engineer\"], \"answer_start\": [27]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4987</th>\n",
       "      <td>Martha is Pakistani and an engineer.</td>\n",
       "      <td>What is Martha's nationality?</td>\n",
       "      <td>{\"text\": [\"Pakistani\"], \"answer_start\": [10]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4988</th>\n",
       "      <td>Martha is an engineer and Pakistani.</td>\n",
       "      <td>What is Martha's job?</td>\n",
       "      <td>{\"text\": [\"engineer\"], \"answer_start\": [13]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>Martha is an engineer and Pakistani.</td>\n",
       "      <td>What is Martha's nationality?</td>\n",
       "      <td>{\"text\": [\"Pakistani\"], \"answer_start\": [26]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4990 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                context  \\\n",
       "0                  Catherine is a Bangladeshi waitress.   \n",
       "1                  Catherine is a Bangladeshi waitress.   \n",
       "2     Catherine is a waitress. Catherine is Banglade...   \n",
       "3     Catherine is a waitress. Catherine is Banglade...   \n",
       "4     Catherine is Bangladeshi. Catherine is a waitr...   \n",
       "...                                                 ...   \n",
       "4985        Martha is Pakistani. Martha is an engineer.   \n",
       "4986               Martha is Pakistani and an engineer.   \n",
       "4987               Martha is Pakistani and an engineer.   \n",
       "4988               Martha is an engineer and Pakistani.   \n",
       "4989               Martha is an engineer and Pakistani.   \n",
       "\n",
       "                              question  \\\n",
       "0             What is Catherine's job?   \n",
       "1     What is Catherine's nationality?   \n",
       "2             What is Catherine's job?   \n",
       "3     What is Catherine's nationality?   \n",
       "4             What is Catherine's job?   \n",
       "...                                ...   \n",
       "4985     What is Martha's nationality?   \n",
       "4986             What is Martha's job?   \n",
       "4987     What is Martha's nationality?   \n",
       "4988             What is Martha's job?   \n",
       "4989     What is Martha's nationality?   \n",
       "\n",
       "                                              answers  \n",
       "0        {\"text\": [\"waitress\"], \"answer_start\": [27]}  \n",
       "1     {\"text\": [\"Bangladeshi\"], \"answer_start\": [15]}  \n",
       "2        {\"text\": [\"waitress\"], \"answer_start\": [15]}  \n",
       "3     {\"text\": [\"Bangladeshi\"], \"answer_start\": [38]}  \n",
       "4        {\"text\": [\"waitress\"], \"answer_start\": [41]}  \n",
       "...                                               ...  \n",
       "4985    {\"text\": [\"Pakistani\"], \"answer_start\": [10]}  \n",
       "4986     {\"text\": [\"engineer\"], \"answer_start\": [27]}  \n",
       "4987    {\"text\": [\"Pakistani\"], \"answer_start\": [10]}  \n",
       "4988     {\"text\": [\"engineer\"], \"answer_start\": [13]}  \n",
       "4989    {\"text\": [\"Pakistani\"], \"answer_start\": [26]}  \n",
       "\n",
       "[4990 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"profession_nationality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animal vs vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = ['dog', 'cat', 'bull', 'cow', 'fish', 'serpent', 'snake', 'lizard', 'hamster', 'rabbit', 'guinea pig', 'iguana', 'duck']\n",
    "vehicles = ['car', 'truck', 'train', 'motorcycle', 'bike', 'firetruck', 'tractor', 'van', 'SUV', 'minivan']\n",
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} has {a:animal} and {a:vehicle}.',\n",
    "            '{first_name} has {a:vehicle} and {a:animal}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'What animal does {first_name} have?',\n",
    "                '{animal}'\n",
    "            ), \n",
    "            (\n",
    "                'What vehicle does {first_name} have?',\n",
    "                '{vehicle}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    animal=animals,\n",
    "    vehicle=vehicles,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))\n",
    "name = 'Animal vs Vehicle'\n",
    "# test = MFT(**t, name=name, description='', capability='Taxonomy', expect=expect_squad)\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jessica has a bull and a motorcycle.</td>\n",
       "      <td>What animal does Jessica have?</td>\n",
       "      <td>{\"text\": [\"bull\"], \"answer_start\": [14]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jessica has a bull and a motorcycle.</td>\n",
       "      <td>What vehicle does Jessica have?</td>\n",
       "      <td>{\"text\": [\"motorcycle\"], \"answer_start\": [25]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jessica has a motorcycle and a bull.</td>\n",
       "      <td>What animal does Jessica have?</td>\n",
       "      <td>{\"text\": [\"bull\"], \"answer_start\": [31]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jessica has a motorcycle and a bull.</td>\n",
       "      <td>What vehicle does Jessica have?</td>\n",
       "      <td>{\"text\": [\"motorcycle\"], \"answer_start\": [14]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jonathan has a bull and a minivan.</td>\n",
       "      <td>What animal does Jonathan have?</td>\n",
       "      <td>{\"text\": [\"bull\"], \"answer_start\": [15]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>Larry has a tractor and a lizard.</td>\n",
       "      <td>What vehicle does Larry have?</td>\n",
       "      <td>{\"text\": [\"tractor\"], \"answer_start\": [12]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>Thomas has an iguana and a tractor.</td>\n",
       "      <td>What animal does Thomas have?</td>\n",
       "      <td>{\"text\": [\"iguana\"], \"answer_start\": [14]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>Thomas has an iguana and a tractor.</td>\n",
       "      <td>What vehicle does Thomas have?</td>\n",
       "      <td>{\"text\": [\"tractor\"], \"answer_start\": [27]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>Thomas has a tractor and an iguana.</td>\n",
       "      <td>What animal does Thomas have?</td>\n",
       "      <td>{\"text\": [\"iguana\"], \"answer_start\": [28]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>Thomas has a tractor and an iguana.</td>\n",
       "      <td>What vehicle does Thomas have?</td>\n",
       "      <td>{\"text\": [\"tractor\"], \"answer_start\": [13]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1976 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   context                         question  \\\n",
       "0     Jessica has a bull and a motorcycle.   What animal does Jessica have?   \n",
       "1     Jessica has a bull and a motorcycle.  What vehicle does Jessica have?   \n",
       "2     Jessica has a motorcycle and a bull.   What animal does Jessica have?   \n",
       "3     Jessica has a motorcycle and a bull.  What vehicle does Jessica have?   \n",
       "4       Jonathan has a bull and a minivan.  What animal does Jonathan have?   \n",
       "...                                    ...                              ...   \n",
       "1971     Larry has a tractor and a lizard.    What vehicle does Larry have?   \n",
       "1972   Thomas has an iguana and a tractor.    What animal does Thomas have?   \n",
       "1973   Thomas has an iguana and a tractor.   What vehicle does Thomas have?   \n",
       "1974   Thomas has a tractor and an iguana.    What animal does Thomas have?   \n",
       "1975   Thomas has a tractor and an iguana.   What vehicle does Thomas have?   \n",
       "\n",
       "                                             answers  \n",
       "0           {\"text\": [\"bull\"], \"answer_start\": [14]}  \n",
       "1     {\"text\": [\"motorcycle\"], \"answer_start\": [25]}  \n",
       "2           {\"text\": [\"bull\"], \"answer_start\": [31]}  \n",
       "3     {\"text\": [\"motorcycle\"], \"answer_start\": [14]}  \n",
       "4           {\"text\": [\"bull\"], \"answer_start\": [15]}  \n",
       "...                                              ...  \n",
       "1971     {\"text\": [\"tractor\"], \"answer_start\": [12]}  \n",
       "1972      {\"text\": [\"iguana\"], \"answer_start\": [14]}  \n",
       "1973     {\"text\": [\"tractor\"], \"answer_start\": [27]}  \n",
       "1974      {\"text\": [\"iguana\"], \"answer_start\": [28]}  \n",
       "1975     {\"text\": [\"tractor\"], \"answer_start\": [13]}  \n",
       "\n",
       "[1976 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"animal_vehicle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = ['dog', 'cat', 'bull', 'cow', 'fish', 'serpent', 'snake', 'lizard', 'hamster', 'rabbit', 'guinea pig', 'iguana', 'duck']\n",
    "vehicles = ['car', 'truck', 'train', 'motorcycle', 'bike', 'firetruck', 'tractor', 'van', 'SUV', 'minivan']\n",
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} bought {a:animal}. {first_name2} bought {a:vehicle}.',\n",
    "            '{first_name2} bought {a:vehicle}. {first_name} bought {a:animal}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who bought an animal?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who bought a vehicle?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    animal=animals,\n",
    "    vehicle=vehicles,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))\n",
    "name = 'Animal vs Vehicle v2'\n",
    "# test = MFT(**t, name=name, description='', capability='Taxonomy', expect=expect_squad)\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cynthia bought a lizard. Pamela bought a truck.</td>\n",
       "      <td>Who bought an animal?</td>\n",
       "      <td>{\"text\": [\"Cynthia\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cynthia bought a lizard. Pamela bought a truck.</td>\n",
       "      <td>Who bought a vehicle?</td>\n",
       "      <td>{\"text\": [\"Pamela\"], \"answer_start\": [25]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pamela bought a truck. Cynthia bought a lizard.</td>\n",
       "      <td>Who bought an animal?</td>\n",
       "      <td>{\"text\": [\"Cynthia\"], \"answer_start\": [23]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pamela bought a truck. Cynthia bought a lizard.</td>\n",
       "      <td>Who bought a vehicle?</td>\n",
       "      <td>{\"text\": [\"Pamela\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>David bought a dog. Linda bought a truck.</td>\n",
       "      <td>Who bought an animal?</td>\n",
       "      <td>{\"text\": [\"David\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>Julie bought a firetruck. Grace bought a rabbit.</td>\n",
       "      <td>Who bought a vehicle?</td>\n",
       "      <td>{\"text\": [\"Julie\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>Elizabeth bought a snake. Ruth bought a SUV.</td>\n",
       "      <td>Who bought an animal?</td>\n",
       "      <td>{\"text\": [\"Elizabeth\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>Elizabeth bought a snake. Ruth bought a SUV.</td>\n",
       "      <td>Who bought a vehicle?</td>\n",
       "      <td>{\"text\": [\"Ruth\"], \"answer_start\": [26]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>Ruth bought a SUV. Elizabeth bought a snake.</td>\n",
       "      <td>Who bought an animal?</td>\n",
       "      <td>{\"text\": [\"Elizabeth\"], \"answer_start\": [19]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>Ruth bought a SUV. Elizabeth bought a snake.</td>\n",
       "      <td>Who bought a vehicle?</td>\n",
       "      <td>{\"text\": [\"Ruth\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1992 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               context               question  \\\n",
       "0      Cynthia bought a lizard. Pamela bought a truck.  Who bought an animal?   \n",
       "1      Cynthia bought a lizard. Pamela bought a truck.  Who bought a vehicle?   \n",
       "2      Pamela bought a truck. Cynthia bought a lizard.  Who bought an animal?   \n",
       "3      Pamela bought a truck. Cynthia bought a lizard.  Who bought a vehicle?   \n",
       "4            David bought a dog. Linda bought a truck.  Who bought an animal?   \n",
       "...                                                ...                    ...   \n",
       "1987  Julie bought a firetruck. Grace bought a rabbit.  Who bought a vehicle?   \n",
       "1988      Elizabeth bought a snake. Ruth bought a SUV.  Who bought an animal?   \n",
       "1989      Elizabeth bought a snake. Ruth bought a SUV.  Who bought a vehicle?   \n",
       "1990      Ruth bought a SUV. Elizabeth bought a snake.  Who bought an animal?   \n",
       "1991      Ruth bought a SUV. Elizabeth bought a snake.  Who bought a vehicle?   \n",
       "\n",
       "                                            answers  \n",
       "0        {\"text\": [\"Cynthia\"], \"answer_start\": [0]}  \n",
       "1        {\"text\": [\"Pamela\"], \"answer_start\": [25]}  \n",
       "2       {\"text\": [\"Cynthia\"], \"answer_start\": [23]}  \n",
       "3         {\"text\": [\"Pamela\"], \"answer_start\": [0]}  \n",
       "4          {\"text\": [\"David\"], \"answer_start\": [0]}  \n",
       "...                                             ...  \n",
       "1987       {\"text\": [\"Julie\"], \"answer_start\": [0]}  \n",
       "1988   {\"text\": [\"Elizabeth\"], \"answer_start\": [0]}  \n",
       "1989       {\"text\": [\"Ruth\"], \"answer_start\": [26]}  \n",
       "1990  {\"text\": [\"Elizabeth\"], \"answer_start\": [19]}  \n",
       "1991        {\"text\": [\"Ruth\"], \"answer_start\": [0]}  \n",
       "\n",
       "[1992 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"animal_vehicle2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonyms = [ ('spiritual', 'religious'), ('angry', 'furious'), ('organized', 'organised'),\n",
    "            ('vocal', 'outspoken'), ('grateful', 'thankful'), ('intelligent', 'smart'),\n",
    "            ('humble', 'modest'), ('courageous', 'brave'), ('happy', 'joyful'), ('scared', 'frightened'),\n",
    "           ]\n",
    "\n",
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is very {s1[0]}. {first_name2} is very {s2[0]}.',\n",
    "            '{first_name2} is very {s2[0]}. {first_name} is very {s1[0]}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {s1[1]}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {s2[1]}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    s=synonyms,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=250,\n",
    "    save=True\n",
    "   ))\n",
    "t += crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is very {s1[1]}. {first_name2} is very {s2[1]}.',\n",
    "            '{first_name2} is very {s2[1]}. {first_name} is very {s1[1]}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {s1[0]}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {s2[0]}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    s=synonyms,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=250,\n",
    "    save=True\n",
    "    )) \n",
    "name = 'Synonyms'\n",
    "# test = MFT(**t, name=name, description='', capability='Taxonomy', expect=expect_squad)\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sam is very angry. Kevin is very vocal.</td>\n",
       "      <td>Who is furious?</td>\n",
       "      <td>{\"text\": [\"Sam\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sam is very angry. Kevin is very vocal.</td>\n",
       "      <td>Who is outspoken?</td>\n",
       "      <td>{\"text\": [\"Kevin\"], \"answer_start\": [19]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kevin is very vocal. Sam is very angry.</td>\n",
       "      <td>Who is furious?</td>\n",
       "      <td>{\"text\": [\"Sam\"], \"answer_start\": [21]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kevin is very vocal. Sam is very angry.</td>\n",
       "      <td>Who is outspoken?</td>\n",
       "      <td>{\"text\": [\"Kevin\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kevin is very spiritual. Sam is very intelligent.</td>\n",
       "      <td>Who is religious?</td>\n",
       "      <td>{\"text\": [\"Kevin\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1847</th>\n",
       "      <td>Michael is very thankful. Betty is very fright...</td>\n",
       "      <td>Who is grateful?</td>\n",
       "      <td>{\"text\": [\"Michael\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>Emma is very brave. Heather is very thankful.</td>\n",
       "      <td>Who is courageous?</td>\n",
       "      <td>{\"text\": [\"Emma\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>Emma is very brave. Heather is very thankful.</td>\n",
       "      <td>Who is grateful?</td>\n",
       "      <td>{\"text\": [\"Heather\"], \"answer_start\": [20]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>Heather is very thankful. Emma is very brave.</td>\n",
       "      <td>Who is courageous?</td>\n",
       "      <td>{\"text\": [\"Emma\"], \"answer_start\": [26]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>Heather is very thankful. Emma is very brave.</td>\n",
       "      <td>Who is grateful?</td>\n",
       "      <td>{\"text\": [\"Heather\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1852 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                context            question  \\\n",
       "0               Sam is very angry. Kevin is very vocal.     Who is furious?   \n",
       "1               Sam is very angry. Kevin is very vocal.   Who is outspoken?   \n",
       "2               Kevin is very vocal. Sam is very angry.     Who is furious?   \n",
       "3               Kevin is very vocal. Sam is very angry.   Who is outspoken?   \n",
       "4     Kevin is very spiritual. Sam is very intelligent.   Who is religious?   \n",
       "...                                                 ...                 ...   \n",
       "1847  Michael is very thankful. Betty is very fright...    Who is grateful?   \n",
       "1848      Emma is very brave. Heather is very thankful.  Who is courageous?   \n",
       "1849      Emma is very brave. Heather is very thankful.    Who is grateful?   \n",
       "1850      Heather is very thankful. Emma is very brave.  Who is courageous?   \n",
       "1851      Heather is very thankful. Emma is very brave.    Who is grateful?   \n",
       "\n",
       "                                          answers  \n",
       "0          {\"text\": [\"Sam\"], \"answer_start\": [0]}  \n",
       "1       {\"text\": [\"Kevin\"], \"answer_start\": [19]}  \n",
       "2         {\"text\": [\"Sam\"], \"answer_start\": [21]}  \n",
       "3        {\"text\": [\"Kevin\"], \"answer_start\": [0]}  \n",
       "4        {\"text\": [\"Kevin\"], \"answer_start\": [0]}  \n",
       "...                                           ...  \n",
       "1847   {\"text\": [\"Michael\"], \"answer_start\": [0]}  \n",
       "1848      {\"text\": [\"Emma\"], \"answer_start\": [0]}  \n",
       "1849  {\"text\": [\"Heather\"], \"answer_start\": [20]}  \n",
       "1850     {\"text\": [\"Emma\"], \"answer_start\": [26]}  \n",
       "1851   {\"text\": [\"Heather\"], \"answer_start\": [0]}  \n",
       "\n",
       "[1852 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"synonyms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_pairs = [('better', 'worse'), ('older', 'younger'), ('smarter', 'dumber'), ('taller', 'shorter'), ('bigger', 'smaller'), ('stronger', 'weaker'), ('faster', 'slower'), ('darker', 'lighter'), ('richer', 'poorer'), ('happier', 'sadder'), ('louder', 'quieter'), ('warmer', 'colder')]\n",
    "comp_pairs = list(set(comp_pairs))#list(set(comp_pairs + [(x[1], x[0]) for x in comp_pairs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is {comp[0]} than {first_name1}.',\n",
    "            '{first_name1} is {comp[1]} than {first_name}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {comp[1]}?',\n",
    "                '{first_name1}',\n",
    "            ),\n",
    "            (\n",
    "                'Who is {comp[0]}?',\n",
    "                '{first_name}',\n",
    "            )\n",
    "            \n",
    "        ]\n",
    "        ,\n",
    "    },\n",
    "    comp=comp_pairs,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))\n",
    "name = 'A is COMP than B. Who is antonym(COMP)? B'\n",
    "# test = MFT(**t, name=name, description='', capability='Taxonomy')\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Frederick is better than Dorothy.</td>\n",
       "      <td>Who is worse?</td>\n",
       "      <td>{\"text\": [\"Dorothy\"], \"answer_start\": [25]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Frederick is better than Dorothy.</td>\n",
       "      <td>Who is better?</td>\n",
       "      <td>{\"text\": [\"Frederick\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dorothy is worse than Frederick.</td>\n",
       "      <td>Who is worse?</td>\n",
       "      <td>{\"text\": [\"Dorothy\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dorothy is worse than Frederick.</td>\n",
       "      <td>Who is better?</td>\n",
       "      <td>{\"text\": [\"Frederick\"], \"answer_start\": [22]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sally is faster than Tom.</td>\n",
       "      <td>Who is slower?</td>\n",
       "      <td>{\"text\": [\"Tom\"], \"answer_start\": [21]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>Judy is younger than Cynthia.</td>\n",
       "      <td>Who is older?</td>\n",
       "      <td>{\"text\": [\"Cynthia\"], \"answer_start\": [21]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>Joseph is stronger than Anna.</td>\n",
       "      <td>Who is weaker?</td>\n",
       "      <td>{\"text\": [\"Anna\"], \"answer_start\": [24]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>Joseph is stronger than Anna.</td>\n",
       "      <td>Who is stronger?</td>\n",
       "      <td>{\"text\": [\"Joseph\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>Anna is weaker than Joseph.</td>\n",
       "      <td>Who is weaker?</td>\n",
       "      <td>{\"text\": [\"Anna\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>Anna is weaker than Joseph.</td>\n",
       "      <td>Who is stronger?</td>\n",
       "      <td>{\"text\": [\"Joseph\"], \"answer_start\": [20]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1976 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                context          question  \\\n",
       "0     Frederick is better than Dorothy.     Who is worse?   \n",
       "1     Frederick is better than Dorothy.    Who is better?   \n",
       "2      Dorothy is worse than Frederick.     Who is worse?   \n",
       "3      Dorothy is worse than Frederick.    Who is better?   \n",
       "4             Sally is faster than Tom.    Who is slower?   \n",
       "...                                 ...               ...   \n",
       "1971      Judy is younger than Cynthia.     Who is older?   \n",
       "1972      Joseph is stronger than Anna.    Who is weaker?   \n",
       "1973      Joseph is stronger than Anna.  Who is stronger?   \n",
       "1974        Anna is weaker than Joseph.    Who is weaker?   \n",
       "1975        Anna is weaker than Joseph.  Who is stronger?   \n",
       "\n",
       "                                            answers  \n",
       "0       {\"text\": [\"Dorothy\"], \"answer_start\": [25]}  \n",
       "1      {\"text\": [\"Frederick\"], \"answer_start\": [0]}  \n",
       "2        {\"text\": [\"Dorothy\"], \"answer_start\": [0]}  \n",
       "3     {\"text\": [\"Frederick\"], \"answer_start\": [22]}  \n",
       "4           {\"text\": [\"Tom\"], \"answer_start\": [21]}  \n",
       "...                                             ...  \n",
       "1971    {\"text\": [\"Cynthia\"], \"answer_start\": [21]}  \n",
       "1972       {\"text\": [\"Anna\"], \"answer_start\": [24]}  \n",
       "1973      {\"text\": [\"Joseph\"], \"answer_start\": [0]}  \n",
       "1974        {\"text\": [\"Anna\"], \"answer_start\": [0]}  \n",
       "1975     {\"text\": [\"Joseph\"], \"answer_start\": [20]}  \n",
       "\n",
       "[1976 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"compare_antonym\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "antonym_adjs = [('progressive', 'conservative'),('religious', 'secular'),('positive', 'negative'),('defensive', 'offensive'),('rude',  'polite'),('optimistic', 'pessimistic'),('stupid', 'smart'),('negative', 'positive'),('unhappy', 'happy'),('active', 'passive'),('impatient', 'patient'),('powerless', 'powerful'),('visible', 'invisible'),('fat', 'thin'),('bad', 'good'),('cautious', 'brave'), ('hopeful', 'hopeless'),('insecure', 'secure'),('humble', 'proud'),('passive', 'active'),('dependent', 'independent'),('pessimistic', 'optimistic'),('irresponsible', 'responsible'),('courageous', 'fearful')]\n",
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is more {a[0]} than {first_name1}.',\n",
    "            '{first_name1} is more {a[1]} than {first_name}.',\n",
    "            '{first_name} is less {a[1]} than {first_name1}.',\n",
    "            '{first_name1} is less {a[0]} than {first_name}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is more {a[0]}?',\n",
    "                '{first_name}',\n",
    "            ),\n",
    "            (\n",
    "                'Who is less {a[0]}?',\n",
    "                '{first_name1}',\n",
    "            ),\n",
    "            (\n",
    "                'Who is more {a[1]}?',\n",
    "                '{first_name1}',\n",
    "            ),\n",
    "            (\n",
    "                'Who is less {a[1]}?',\n",
    "                '{first_name}',\n",
    "            ),\n",
    "        ]\n",
    "        ,\n",
    "    },\n",
    "    a = antonym_adjs,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))\n",
    "name = 'A is more X than B. Who is more antonym(X)? B. Who is less X? B. Who is more X? A. Who is less antonym(X)? A.'\n",
    "# test = MFT(**t, name=name, description='', capability='Taxonomy')\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stephen is more courageous than Leslie.</td>\n",
       "      <td>Who is more courageous?</td>\n",
       "      <td>{\"text\": [\"Stephen\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stephen is more courageous than Leslie.</td>\n",
       "      <td>Who is less courageous?</td>\n",
       "      <td>{\"text\": [\"Leslie\"], \"answer_start\": [32]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stephen is more courageous than Leslie.</td>\n",
       "      <td>Who is more fearful?</td>\n",
       "      <td>{\"text\": [\"Leslie\"], \"answer_start\": [32]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stephen is more courageous than Leslie.</td>\n",
       "      <td>Who is less fearful?</td>\n",
       "      <td>{\"text\": [\"Stephen\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leslie is more fearful than Stephen.</td>\n",
       "      <td>Who is more courageous?</td>\n",
       "      <td>{\"text\": [\"Stephen\"], \"answer_start\": [28]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7979</th>\n",
       "      <td>Charlie is less secure than Fred.</td>\n",
       "      <td>Who is less secure?</td>\n",
       "      <td>{\"text\": [\"Charlie\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7980</th>\n",
       "      <td>Fred is less insecure than Charlie.</td>\n",
       "      <td>Who is more insecure?</td>\n",
       "      <td>{\"text\": [\"Charlie\"], \"answer_start\": [27]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7981</th>\n",
       "      <td>Fred is less insecure than Charlie.</td>\n",
       "      <td>Who is less insecure?</td>\n",
       "      <td>{\"text\": [\"Fred\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7982</th>\n",
       "      <td>Fred is less insecure than Charlie.</td>\n",
       "      <td>Who is more secure?</td>\n",
       "      <td>{\"text\": [\"Fred\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7983</th>\n",
       "      <td>Fred is less insecure than Charlie.</td>\n",
       "      <td>Who is less secure?</td>\n",
       "      <td>{\"text\": [\"Charlie\"], \"answer_start\": [27]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7984 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      context                 question  \\\n",
       "0     Stephen is more courageous than Leslie.  Who is more courageous?   \n",
       "1     Stephen is more courageous than Leslie.  Who is less courageous?   \n",
       "2     Stephen is more courageous than Leslie.     Who is more fearful?   \n",
       "3     Stephen is more courageous than Leslie.     Who is less fearful?   \n",
       "4        Leslie is more fearful than Stephen.  Who is more courageous?   \n",
       "...                                       ...                      ...   \n",
       "7979        Charlie is less secure than Fred.      Who is less secure?   \n",
       "7980      Fred is less insecure than Charlie.    Who is more insecure?   \n",
       "7981      Fred is less insecure than Charlie.    Who is less insecure?   \n",
       "7982      Fred is less insecure than Charlie.      Who is more secure?   \n",
       "7983      Fred is less insecure than Charlie.      Who is less secure?   \n",
       "\n",
       "                                          answers  \n",
       "0      {\"text\": [\"Stephen\"], \"answer_start\": [0]}  \n",
       "1      {\"text\": [\"Leslie\"], \"answer_start\": [32]}  \n",
       "2      {\"text\": [\"Leslie\"], \"answer_start\": [32]}  \n",
       "3      {\"text\": [\"Stephen\"], \"answer_start\": [0]}  \n",
       "4     {\"text\": [\"Stephen\"], \"answer_start\": [28]}  \n",
       "...                                           ...  \n",
       "7979   {\"text\": [\"Charlie\"], \"answer_start\": [0]}  \n",
       "7980  {\"text\": [\"Charlie\"], \"answer_start\": [27]}  \n",
       "7981      {\"text\": [\"Fred\"], \"answer_start\": [0]}  \n",
       "7982      {\"text\": [\"Fred\"], \"answer_start\": [0]}  \n",
       "7983  {\"text\": [\"Charlie\"], \"answer_start\": [27]}  \n",
       "\n",
       "[7984 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"compare_moreless_antonym\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [(x['context'], x['question']) for x in dataset['train']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "spacy_map =  pickle.load(open('processed_squad.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_pairs = [(spacy_map[x[0]], spacy_map[x[1]]) for x in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_typo(x):\n",
    "    \"\"\"\n",
    "    x[0]: context\n",
    "    x[1]: question \n",
    "    Perturb.add_typos(x[1]): add a typo to question \n",
    "    \"\"\"\n",
    "    return (x[0], Perturb.add_typos(x[1]))\n",
    "t = Perturb.perturb(pairs, question_typo, nsamples=500)\n",
    "# test = INV(**t, name='Question typo', capability='Robustness', description='')\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad)\n",
    "# suite.add(test, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On the other hand, in his study on nine of \"th...</td>\n",
       "      <td>BeDuhn clarifies that the differencesa re actu...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"greater accuracy\\\"], \\\"answer_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>People can be exposed to asphalt in the workpl...</td>\n",
       "      <td>How must asphalt be tretaed to be workable?</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"heated or diluted\\\"], \\\"answer_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In the past, Qutb Shahi rulers and Nizams attr...</td>\n",
       "      <td>When was Lazzat UnN isa completed?</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"the 15th century\\\"], \\\"answer_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Every major company selling the antipsychotics...</td>\n",
       "      <td>Pfizer settled th eGeodon lawsuit for how much...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"$301 million\\\"], \\\"answer_start...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arsenal fans often refer to themselves as \"Goo...</td>\n",
       "      <td>Where did the attenadnce at Arsenal games rank...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"second-highest average\\\"], \\\"an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>St. John's is one of the oldest settlements in...</td>\n",
       "      <td>Which cityi s considered one of the oldest set...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"St. John's\\\"], \\\"answer_start\\\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Species that have no long-distance migratory r...</td>\n",
       "      <td>What species has no long-distanc emigratory re...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"the waxwings Bombycilla\\\"], \\\"a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>The names for the nation of Greece and the Gre...</td>\n",
       "      <td>From what owrd is Greece derived?</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"Graecia\\\"], \\\"answer_start\\\": [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>In the United Kingdom, sociologists and other ...</td>\n",
       "      <td>What made up Leisrue activities and goods as v...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"art, music, film, food, sports,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>More than 12,000 miles (19,000 km) of roads ma...</td>\n",
       "      <td>Oklahoma has thel ongest drivable stretch of w...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"Route 66\\\"], \\\"answer_start\\\": ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               context  \\\n",
       "0    On the other hand, in his study on nine of \"th...   \n",
       "1    People can be exposed to asphalt in the workpl...   \n",
       "2    In the past, Qutb Shahi rulers and Nizams attr...   \n",
       "3    Every major company selling the antipsychotics...   \n",
       "4    Arsenal fans often refer to themselves as \"Goo...   \n",
       "..                                                 ...   \n",
       "495  St. John's is one of the oldest settlements in...   \n",
       "496  Species that have no long-distance migratory r...   \n",
       "497  The names for the nation of Greece and the Gre...   \n",
       "498  In the United Kingdom, sociologists and other ...   \n",
       "499  More than 12,000 miles (19,000 km) of roads ma...   \n",
       "\n",
       "                                              question  \\\n",
       "0    BeDuhn clarifies that the differencesa re actu...   \n",
       "1          How must asphalt be tretaed to be workable?   \n",
       "2                   When was Lazzat UnN isa completed?   \n",
       "3    Pfizer settled th eGeodon lawsuit for how much...   \n",
       "4    Where did the attenadnce at Arsenal games rank...   \n",
       "..                                                 ...   \n",
       "495  Which cityi s considered one of the oldest set...   \n",
       "496  What species has no long-distanc emigratory re...   \n",
       "497                  From what owrd is Greece derived?   \n",
       "498  What made up Leisrue activities and goods as v...   \n",
       "499  Oklahoma has thel ongest drivable stretch of w...   \n",
       "\n",
       "                                               answers  \n",
       "0    \"{\\\"text\\\": [\\\"greater accuracy\\\"], \\\"answer_s...  \n",
       "1    \"{\\\"text\\\": [\\\"heated or diluted\\\"], \\\"answer_...  \n",
       "2    \"{\\\"text\\\": [\\\"the 15th century\\\"], \\\"answer_s...  \n",
       "3    \"{\\\"text\\\": [\\\"$301 million\\\"], \\\"answer_start...  \n",
       "4    \"{\\\"text\\\": [\\\"second-highest average\\\"], \\\"an...  \n",
       "..                                                 ...  \n",
       "495  \"{\\\"text\\\": [\\\"St. John's\\\"], \\\"answer_start\\\"...  \n",
       "496  \"{\\\"text\\\": [\\\"the waxwings Bombycilla\\\"], \\\"a...  \n",
       "497  \"{\\\"text\\\": [\\\"Graecia\\\"], \\\"answer_start\\\": [...  \n",
       "498  \"{\\\"text\\\": [\\\"art, music, film, food, sports,...  \n",
       "499  \"{\\\"text\\\": [\\\"Route 66\\\"], \\\"answer_start\\\": ...  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_dataset_fmt(t, 'typo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contractions(x):\n",
    "    conts = Perturb.contractions(x[1])\n",
    "    return [(x[0], a) for a in conts]\n",
    "t = Perturb.perturb(pairs, contractions, nsamples=500)\n",
    "# test = INV(**t, name='Question contractions', capability='Robustness', description='')\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad)\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Consistent with the missions and priorities ou...</td>\n",
       "      <td>What diplomatic effort does the CAF perform as...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"relationship-building efforts\\\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lateral-cut disc records were developed in the...</td>\n",
       "      <td>What's the name of lateral cut disc records?</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"gramophone\\\"], \\\"answer_start\\\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The bandwidth characteristics of a resonant an...</td>\n",
       "      <td>What's the largest Q that could be achieved wi...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"15\\\"], \\\"answer_start\\\": [980]}\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Until the 1950s guns firing ballistic munition...</td>\n",
       "      <td>Which range didn't use guided missiles?</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"the very shortest ranges\\\"], \\\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The \"Jeltoqsan\" (Kazakh for \"December\") of 198...</td>\n",
       "      <td>What's the English translation of the word Jel...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"December\\\"], \\\"answer_start\\\": ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>The Cineteca Nacional (the Mexican Film Librar...</td>\n",
       "      <td>Where's the Mexican Film Library located?</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"near the Coyoac\\\\u00e1n suburb\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>The transcribed pre-mRNA contains untranslated...</td>\n",
       "      <td>What's at both ends of the transcribed pre-mRNA?</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"untranslated regions\\\"], \\\"answ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>In the 20th century, Greek composers have had ...</td>\n",
       "      <td>Who's one of the notable Greek opera singers i...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"Maria Callas\\\"], \\\"answer_start...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Students attending BYU are required to follow ...</td>\n",
       "      <td>What's the source of much of BYU's funding?</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"the church's tithing funds\\\"], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>According to the 2000 edition of a popular phy...</td>\n",
       "      <td>What're probably the primary forces of nature ...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"selective forces of climate\\\"],...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               context  \\\n",
       "0    Consistent with the missions and priorities ou...   \n",
       "1    Lateral-cut disc records were developed in the...   \n",
       "2    The bandwidth characteristics of a resonant an...   \n",
       "3    Until the 1950s guns firing ballistic munition...   \n",
       "4    The \"Jeltoqsan\" (Kazakh for \"December\") of 198...   \n",
       "..                                                 ...   \n",
       "495  The Cineteca Nacional (the Mexican Film Librar...   \n",
       "496  The transcribed pre-mRNA contains untranslated...   \n",
       "497  In the 20th century, Greek composers have had ...   \n",
       "498  Students attending BYU are required to follow ...   \n",
       "499  According to the 2000 edition of a popular phy...   \n",
       "\n",
       "                                              question  \\\n",
       "0    What diplomatic effort does the CAF perform as...   \n",
       "1         What's the name of lateral cut disc records?   \n",
       "2    What's the largest Q that could be achieved wi...   \n",
       "3              Which range didn't use guided missiles?   \n",
       "4    What's the English translation of the word Jel...   \n",
       "..                                                 ...   \n",
       "495          Where's the Mexican Film Library located?   \n",
       "496   What's at both ends of the transcribed pre-mRNA?   \n",
       "497  Who's one of the notable Greek opera singers i...   \n",
       "498        What's the source of much of BYU's funding?   \n",
       "499  What're probably the primary forces of nature ...   \n",
       "\n",
       "                                               answers  \n",
       "0    \"{\\\"text\\\": [\\\"relationship-building efforts\\\"...  \n",
       "1    \"{\\\"text\\\": [\\\"gramophone\\\"], \\\"answer_start\\\"...  \n",
       "2      \"{\\\"text\\\": [\\\"15\\\"], \\\"answer_start\\\": [980]}\"  \n",
       "3    \"{\\\"text\\\": [\\\"the very shortest ranges\\\"], \\\"...  \n",
       "4    \"{\\\"text\\\": [\\\"December\\\"], \\\"answer_start\\\": ...  \n",
       "..                                                 ...  \n",
       "495  \"{\\\"text\\\": [\\\"near the Coyoac\\\\u00e1n suburb\\...  \n",
       "496  \"{\\\"text\\\": [\\\"untranslated regions\\\"], \\\"answ...  \n",
       "497  \"{\\\"text\\\": [\\\"Maria Callas\\\"], \\\"answer_start...  \n",
       "498  \"{\\\"text\\\": [\\\"the church's tithing funds\\\"], ...  \n",
       "499  \"{\\\"text\\\": [\\\"selective forces of climate\\\"],...  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_dataset_fmt(t, 'contractions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add random sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sentences = set()\n",
    "for x, _ in processed_pairs:\n",
    "    for y in x.sents:\n",
    "        random_sentences.add(y.text)\n",
    "random_sentences = list(random_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_random_sentence(x, **kwargs):\n",
    "    random_s = np.random.choice(random_sentences)\n",
    "    while random_s in x[0]:\n",
    "        random_s = np.random.choice(random_sentences)\n",
    "    random_s = random_s.strip('.') + '. '\n",
    "    meta = ['add to end: %s' % random_s, 'add to beg: %s' % random_s]\n",
    "    return [(x[0] + random_s, x[1]), (random_s + x[0], x[1])], meta\n",
    "\n",
    "t = Perturb.perturb(pairs, add_random_sentence, nsamples=500, meta=True)\n",
    "# test = INV(**t, name='Add random sentence to context', capability='Robustness', description='')\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_add)\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As for Mac OS, System 7 was a 32-bit rewrite f...</td>\n",
       "      <td>How did the Mac System 7 improve multitasking?</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"co-operative multitasking\\\"], \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>During the Hellenistic period, Judea became a ...</td>\n",
       "      <td>What religion rose in Judea durring the Hellen...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"Judaism\\\"], \\\"answer_start\\\": [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Historically, the cuisine of Estonia has been ...</td>\n",
       "      <td>What food gathering behaviors are now seen as ...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"Hunting and fishing\\\"], \\\"answe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ptolemy's Geography divided Asia on a similar ...</td>\n",
       "      <td>\"India on this side of the Ganges\" is located ...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"To the south\\\"], \\\"answer_start...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Energy transformations in the universe over ti...</td>\n",
       "      <td>What is a process ultimately using the gravita...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"nucleosynthesis\\\"], \\\"answer_st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>The method of execution of federal prisoners f...</td>\n",
       "      <td>According to what law are federal prisoners ex...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"Violent Crime Control and Law E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Rapid environmental changes typically cause ma...</td>\n",
       "      <td>How many species currently live on earth?</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"Earth's current species range f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Religious beliefs in the Eastern Empire and Pe...</td>\n",
       "      <td>In what yer did Muhammad die?</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"632\\\"], \\\"answer_start\\\": [468]}\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>The annual Southampton Boat Show is held in Se...</td>\n",
       "      <td>What Southampton festival culminates in the Bo...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"Sea City\\\"], \\\"answer_start\\\": ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Dog behavior is the internally coordinated res...</td>\n",
       "      <td>Dog minds have been shaped by thousands of yea...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"humans.\\\"], \\\"answer_start\\\": [...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               context  \\\n",
       "0    As for Mac OS, System 7 was a 32-bit rewrite f...   \n",
       "1    During the Hellenistic period, Judea became a ...   \n",
       "2    Historically, the cuisine of Estonia has been ...   \n",
       "3    Ptolemy's Geography divided Asia on a similar ...   \n",
       "4    Energy transformations in the universe over ti...   \n",
       "..                                                 ...   \n",
       "495  The method of execution of federal prisoners f...   \n",
       "496  Rapid environmental changes typically cause ma...   \n",
       "497  Religious beliefs in the Eastern Empire and Pe...   \n",
       "498  The annual Southampton Boat Show is held in Se...   \n",
       "499  Dog behavior is the internally coordinated res...   \n",
       "\n",
       "                                              question  \\\n",
       "0       How did the Mac System 7 improve multitasking?   \n",
       "1    What religion rose in Judea durring the Hellen...   \n",
       "2    What food gathering behaviors are now seen as ...   \n",
       "3    \"India on this side of the Ganges\" is located ...   \n",
       "4    What is a process ultimately using the gravita...   \n",
       "..                                                 ...   \n",
       "495  According to what law are federal prisoners ex...   \n",
       "496          How many species currently live on earth?   \n",
       "497                      In what yer did Muhammad die?   \n",
       "498  What Southampton festival culminates in the Bo...   \n",
       "499  Dog minds have been shaped by thousands of yea...   \n",
       "\n",
       "                                               answers  \n",
       "0    \"{\\\"text\\\": [\\\"co-operative multitasking\\\"], \\...  \n",
       "1    \"{\\\"text\\\": [\\\"Judaism\\\"], \\\"answer_start\\\": [...  \n",
       "2    \"{\\\"text\\\": [\\\"Hunting and fishing\\\"], \\\"answe...  \n",
       "3    \"{\\\"text\\\": [\\\"To the south\\\"], \\\"answer_start...  \n",
       "4    \"{\\\"text\\\": [\\\"nucleosynthesis\\\"], \\\"answer_st...  \n",
       "..                                                 ...  \n",
       "495  \"{\\\"text\\\": [\\\"Violent Crime Control and Law E...  \n",
       "496  \"{\\\"text\\\": [\\\"Earth's current species range f...  \n",
       "497   \"{\\\"text\\\": [\\\"632\\\"], \\\"answer_start\\\": [468]}\"  \n",
       "498  \"{\\\"text\\\": [\\\"Sea City\\\"], \\\"answer_start\\\": ...  \n",
       "499  \"{\\\"text\\\": [\\\"humans.\\\"], \\\"answer_start\\\": [...  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_dataset_fmt(t, 'random_sentence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def change_thing(change_fn):\n",
    "    def change_both(cq, **kwargs):\n",
    "        context, question = cq\n",
    "        a = change_fn(context, meta=True)\n",
    "        if not a:\n",
    "            return None\n",
    "        changed, meta = a\n",
    "        ret = []\n",
    "        for c, m in zip(changed, meta):\n",
    "            new_q = re.sub(r'\\b%s\\b' % re.escape(m[0]), m[1], question.text)\n",
    "            ret.append((c, new_q))\n",
    "        return ret, meta\n",
    "    return change_both\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Perturb.perturb(processed_pairs, change_thing(Perturb.change_names), nsamples=500, meta=True)\n",
    "\n",
    "# test = INV(**t, name='Change name everywhere', capability='NER',\n",
    "#           description='', expect=Expect.pairwise(expect_same))\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(3, format_example_fn=format_replace)\n",
    "# suite.add(test, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>After just 100 hours of ground combat, and wit...</td>\n",
       "      <td>Why did Coalition nations fear the removal of ...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"it would create a power vacuum ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mithridates the Great was the ruler of Pontus,...</td>\n",
       "      <td>How many Romans lived in Mithridate the Great'...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"80,000\\\"], \\\"answer_start\\\": [3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>On 6 September 2007, Belgian-based Internation...</td>\n",
       "      <td>How much did the Princess Elizabeth station cost?</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"$16.3 million\\\"], \\\"answer_star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On September 13, 2009, during the 2009 MTV Vid...</td>\n",
       "      <td>What artist's award reception did Kanye interr...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"Taylor Swift\\\"], \\\"answer_start...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eisenhower returned to the U.S. in December 19...</td>\n",
       "      <td>What event contributed to Eisenhower receiving...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"Louisiana Maneuvers\\\"], \\\"answe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>An alternative view offered by Michael Sanders...</td>\n",
       "      <td>To what part of the prey does Michael Sanders ...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"the body\\\"], \\\"answer_start\\\": ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Beyoncé's vocal range spans four octaves. Jody...</td>\n",
       "      <td>New York Times' Jon Pareles calls Beyoncé's vo...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"tart\\\"], \\\"answer_start\\\": [630]}\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>In 1867, the university opened the first priva...</td>\n",
       "      <td>When did Washington University establish its m...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"1891\\\"], \\\"answer_start\\\": [290]}\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>The team worked on a Wii control scheme, adapt...</td>\n",
       "      <td>What kind of movement interfaced with the swor...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"swinging gesture\\\"], \\\"answer_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>Following the Ulm Campaign, French forces mana...</td>\n",
       "      <td>How many muskets did the French capture in th...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"100,000\\\"], \\\"answer_start\\\": [...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               context  \\\n",
       "0    After just 100 hours of ground combat, and wit...   \n",
       "1    Mithridates the Great was the ruler of Pontus,...   \n",
       "2    On 6 September 2007, Belgian-based Internation...   \n",
       "3    On September 13, 2009, during the 2009 MTV Vid...   \n",
       "4    Eisenhower returned to the U.S. in December 19...   \n",
       "..                                                 ...   \n",
       "495  An alternative view offered by Michael Sanders...   \n",
       "496  Beyoncé's vocal range spans four octaves. Jody...   \n",
       "497  In 1867, the university opened the first priva...   \n",
       "498  The team worked on a Wii control scheme, adapt...   \n",
       "499  Following the Ulm Campaign, French forces mana...   \n",
       "\n",
       "                                              question  \\\n",
       "0    Why did Coalition nations fear the removal of ...   \n",
       "1    How many Romans lived in Mithridate the Great'...   \n",
       "2    How much did the Princess Elizabeth station cost?   \n",
       "3    What artist's award reception did Kanye interr...   \n",
       "4    What event contributed to Eisenhower receiving...   \n",
       "..                                                 ...   \n",
       "495  To what part of the prey does Michael Sanders ...   \n",
       "496  New York Times' Jon Pareles calls Beyoncé's vo...   \n",
       "497  When did Washington University establish its m...   \n",
       "498  What kind of movement interfaced with the swor...   \n",
       "499   How many muskets did the French capture in th...   \n",
       "\n",
       "                                               answers  \n",
       "0    \"{\\\"text\\\": [\\\"it would create a power vacuum ...  \n",
       "1    \"{\\\"text\\\": [\\\"80,000\\\"], \\\"answer_start\\\": [3...  \n",
       "2    \"{\\\"text\\\": [\\\"$16.3 million\\\"], \\\"answer_star...  \n",
       "3    \"{\\\"text\\\": [\\\"Taylor Swift\\\"], \\\"answer_start...  \n",
       "4    \"{\\\"text\\\": [\\\"Louisiana Maneuvers\\\"], \\\"answe...  \n",
       "..                                                 ...  \n",
       "495  \"{\\\"text\\\": [\\\"the body\\\"], \\\"answer_start\\\": ...  \n",
       "496  \"{\\\"text\\\": [\\\"tart\\\"], \\\"answer_start\\\": [630]}\"  \n",
       "497  \"{\\\"text\\\": [\\\"1891\\\"], \\\"answer_start\\\": [290]}\"  \n",
       "498  \"{\\\"text\\\": [\\\"swinging gesture\\\"], \\\"answer_s...  \n",
       "499  \"{\\\"text\\\": [\\\"100,000\\\"], \\\"answer_start\\\": [...  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_dataset_fmt(t, 'name_change')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Perturb.perturb(processed_pairs, change_thing(Perturb.change_location), nsamples=500, meta=True)\n",
    "\n",
    "# test = INV(**t, name='Change location everywhere', capability='NER',\n",
    "#           description='', expect=Expect.pairwise(expect_same))\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(3, format_example_fn=format_replace)\n",
    "# suite.add(test, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Argentine activists told a news conference tha...</td>\n",
       "      <td>What is the name of the activist who promised ...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"Jorge Carcavallo\\\"], \\\"answer_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>By 1976, Queen were back in the studio recordi...</td>\n",
       "      <td>What Queen album was released in 1976?</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"A Day at the Races\\\"], \\\"answer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In the 1874 general election, Disraeli was ret...</td>\n",
       "      <td>What removed Catholic Rituals from Anglican se...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"Public Worship Regulation Act 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Imperial College Union, the students' union at...</td>\n",
       "      <td>How long is the tenure for an officer to run t...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"one year\\\"], \\\"answer_start\\\": ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In 2010, 24.9 percent of households reported h...</td>\n",
       "      <td>Percentage of unwed births?</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"56\\\"], \\\"answer_start\\\": [635]}\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Coyotes and big cats have also been known to a...</td>\n",
       "      <td>What big cats in Indonesia also attack dogs?</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"Tigers\\\"], \\\"answer_start\\\": [2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Spectre opened in Germany with $22.45 million ...</td>\n",
       "      <td>How much more did Spectre earn compared with S...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"4%\\\"], \\\"answer_start\\\": [849]}\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Portland is known for being a trailblazer in v...</td>\n",
       "      <td>How many $10+ donations must Portland city cou...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"200\\\"], \\\"answer_start\\\": [257]}\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>The first boardwalk was built in 1870 along a ...</td>\n",
       "      <td>Why was the first boardwalk built in New Orleans?</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"to help hotel owners keep sand ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>St. Louis's primary electrical power source is...</td>\n",
       "      <td>What does St. Louis's main power plant use for...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"coal and natural gas\\\"], \\\"answ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               context  \\\n",
       "0    Argentine activists told a news conference tha...   \n",
       "1    By 1976, Queen were back in the studio recordi...   \n",
       "2    In the 1874 general election, Disraeli was ret...   \n",
       "3    Imperial College Union, the students' union at...   \n",
       "4    In 2010, 24.9 percent of households reported h...   \n",
       "..                                                 ...   \n",
       "495  Coyotes and big cats have also been known to a...   \n",
       "496  Spectre opened in Germany with $22.45 million ...   \n",
       "497  Portland is known for being a trailblazer in v...   \n",
       "498  The first boardwalk was built in 1870 along a ...   \n",
       "499  St. Louis's primary electrical power source is...   \n",
       "\n",
       "                                              question  \\\n",
       "0    What is the name of the activist who promised ...   \n",
       "1               What Queen album was released in 1976?   \n",
       "2    What removed Catholic Rituals from Anglican se...   \n",
       "3    How long is the tenure for an officer to run t...   \n",
       "4                          Percentage of unwed births?   \n",
       "..                                                 ...   \n",
       "495       What big cats in Indonesia also attack dogs?   \n",
       "496  How much more did Spectre earn compared with S...   \n",
       "497  How many $10+ donations must Portland city cou...   \n",
       "498  Why was the first boardwalk built in New Orleans?   \n",
       "499  What does St. Louis's main power plant use for...   \n",
       "\n",
       "                                               answers  \n",
       "0    \"{\\\"text\\\": [\\\"Jorge Carcavallo\\\"], \\\"answer_s...  \n",
       "1    \"{\\\"text\\\": [\\\"A Day at the Races\\\"], \\\"answer...  \n",
       "2    \"{\\\"text\\\": [\\\"Public Worship Regulation Act 1...  \n",
       "3    \"{\\\"text\\\": [\\\"one year\\\"], \\\"answer_start\\\": ...  \n",
       "4      \"{\\\"text\\\": [\\\"56\\\"], \\\"answer_start\\\": [635]}\"  \n",
       "..                                                 ...  \n",
       "495  \"{\\\"text\\\": [\\\"Tigers\\\"], \\\"answer_start\\\": [2...  \n",
       "496    \"{\\\"text\\\": [\\\"4%\\\"], \\\"answer_start\\\": [849]}\"  \n",
       "497   \"{\\\"text\\\": [\\\"200\\\"], \\\"answer_start\\\": [257]}\"  \n",
       "498  \"{\\\"text\\\": [\\\"to help hotel owners keep sand ...  \n",
       "499  \"{\\\"text\\\": [\\\"coal and natural gas\\\"], \\\"answ...  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_dataset_fmt(t, 'location_change')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            'Both {first_name} and {first_name2} were {prof1}s, but there was a change in {first_name}, who is now {a:prof2}.',\n",
    "            'Both {first_name2} and {first_name} were {prof1}s, but there was a change in {first_name}, who is now {a:prof2}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof2}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    ))\n",
    "name = 'There was a change in profession'\n",
    "# test = MFT(**t, expect=expect_squad, capability='Temporal', name=name, description='' )\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Both Suzanne and Kenneth were models, but ther...</td>\n",
       "      <td>Who is a producer?</td>\n",
       "      <td>{\"text\": [\"Suzanne\"], \"answer_start\": [5]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Both Kenneth and Suzanne were models, but ther...</td>\n",
       "      <td>Who is a producer?</td>\n",
       "      <td>{\"text\": [\"Suzanne\"], \"answer_start\": [17]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Both Edith and Kathy were agents, but there wa...</td>\n",
       "      <td>Who is an escort?</td>\n",
       "      <td>{\"text\": [\"Edith\"], \"answer_start\": [5]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Both Kathy and Edith were agents, but there wa...</td>\n",
       "      <td>Who is an escort?</td>\n",
       "      <td>{\"text\": [\"Edith\"], \"answer_start\": [15]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Both David and Adam were organizers, but there...</td>\n",
       "      <td>Who is an interpreter?</td>\n",
       "      <td>{\"text\": [\"David\"], \"answer_start\": [5]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>Both Martha and Howard were educators, but the...</td>\n",
       "      <td>Who is a nurse?</td>\n",
       "      <td>{\"text\": [\"Howard\"], \"answer_start\": [16]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>Both Lawrence and Pamela were reporters, but t...</td>\n",
       "      <td>Who is an educator?</td>\n",
       "      <td>{\"text\": [\"Lawrence\"], \"answer_start\": [5]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>Both Pamela and Lawrence were reporters, but t...</td>\n",
       "      <td>Who is an educator?</td>\n",
       "      <td>{\"text\": [\"Lawrence\"], \"answer_start\": [16]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>Both Lawrence and Carl were attorneys, but the...</td>\n",
       "      <td>Who is an author?</td>\n",
       "      <td>{\"text\": [\"Lawrence\"], \"answer_start\": [5]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>Both Carl and Lawrence were attorneys, but the...</td>\n",
       "      <td>Who is an author?</td>\n",
       "      <td>{\"text\": [\"Lawrence\"], \"answer_start\": [14]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>966 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               context  \\\n",
       "0    Both Suzanne and Kenneth were models, but ther...   \n",
       "1    Both Kenneth and Suzanne were models, but ther...   \n",
       "2    Both Edith and Kathy were agents, but there wa...   \n",
       "3    Both Kathy and Edith were agents, but there wa...   \n",
       "4    Both David and Adam were organizers, but there...   \n",
       "..                                                 ...   \n",
       "961  Both Martha and Howard were educators, but the...   \n",
       "962  Both Lawrence and Pamela were reporters, but t...   \n",
       "963  Both Pamela and Lawrence were reporters, but t...   \n",
       "964  Both Lawrence and Carl were attorneys, but the...   \n",
       "965  Both Carl and Lawrence were attorneys, but the...   \n",
       "\n",
       "                   question                                       answers  \n",
       "0        Who is a producer?    {\"text\": [\"Suzanne\"], \"answer_start\": [5]}  \n",
       "1        Who is a producer?   {\"text\": [\"Suzanne\"], \"answer_start\": [17]}  \n",
       "2         Who is an escort?      {\"text\": [\"Edith\"], \"answer_start\": [5]}  \n",
       "3         Who is an escort?     {\"text\": [\"Edith\"], \"answer_start\": [15]}  \n",
       "4    Who is an interpreter?      {\"text\": [\"David\"], \"answer_start\": [5]}  \n",
       "..                      ...                                           ...  \n",
       "961         Who is a nurse?    {\"text\": [\"Howard\"], \"answer_start\": [16]}  \n",
       "962     Who is an educator?   {\"text\": [\"Lawrence\"], \"answer_start\": [5]}  \n",
       "963     Who is an educator?  {\"text\": [\"Lawrence\"], \"answer_start\": [16]}  \n",
       "964       Who is an author?   {\"text\": [\"Lawrence\"], \"answer_start\": [5]}  \n",
       "965       Who is an author?  {\"text\": [\"Lawrence\"], \"answer_start\": [14]}  \n",
       "\n",
       "[966 rows x 3 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"temproal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} became a {prof} before {first_name2} did.',\n",
    "            '{first_name2} became a {prof} after {first_name} did.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who became a {prof} first?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who became a {prof} last?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    ))\n",
    "name = 'Understanding before / after -> first / last.'\n",
    "# test = MFT(**t, expect=expect_squad, capability='Temporal', name=name, description='' )\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Katherine became a accountant before Alfred did.</td>\n",
       "      <td>Who became a accountant first?</td>\n",
       "      <td>{\"text\": [\"Katherine\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Katherine became a accountant before Alfred did.</td>\n",
       "      <td>Who became a accountant last?</td>\n",
       "      <td>{\"text\": [\"Alfred\"], \"answer_start\": [37]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alfred became a accountant after Katherine did.</td>\n",
       "      <td>Who became a accountant first?</td>\n",
       "      <td>{\"text\": [\"Katherine\"], \"answer_start\": [33]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alfred became a accountant after Katherine did.</td>\n",
       "      <td>Who became a accountant last?</td>\n",
       "      <td>{\"text\": [\"Alfred\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donald became a educator before Thomas did.</td>\n",
       "      <td>Who became a educator first?</td>\n",
       "      <td>{\"text\": [\"Donald\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>Tom became a photographer after Cynthia did.</td>\n",
       "      <td>Who became a photographer last?</td>\n",
       "      <td>{\"text\": [\"Tom\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>Wendy became a nurse before James did.</td>\n",
       "      <td>Who became a nurse first?</td>\n",
       "      <td>{\"text\": [\"Wendy\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>Wendy became a nurse before James did.</td>\n",
       "      <td>Who became a nurse last?</td>\n",
       "      <td>{\"text\": [\"James\"], \"answer_start\": [28]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>James became a nurse after Wendy did.</td>\n",
       "      <td>Who became a nurse first?</td>\n",
       "      <td>{\"text\": [\"Wendy\"], \"answer_start\": [27]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>James became a nurse after Wendy did.</td>\n",
       "      <td>Who became a nurse last?</td>\n",
       "      <td>{\"text\": [\"James\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1996 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               context  \\\n",
       "0     Katherine became a accountant before Alfred did.   \n",
       "1     Katherine became a accountant before Alfred did.   \n",
       "2      Alfred became a accountant after Katherine did.   \n",
       "3      Alfred became a accountant after Katherine did.   \n",
       "4          Donald became a educator before Thomas did.   \n",
       "...                                                ...   \n",
       "1991      Tom became a photographer after Cynthia did.   \n",
       "1992            Wendy became a nurse before James did.   \n",
       "1993            Wendy became a nurse before James did.   \n",
       "1994             James became a nurse after Wendy did.   \n",
       "1995             James became a nurse after Wendy did.   \n",
       "\n",
       "                             question  \\\n",
       "0      Who became a accountant first?   \n",
       "1       Who became a accountant last?   \n",
       "2      Who became a accountant first?   \n",
       "3       Who became a accountant last?   \n",
       "4        Who became a educator first?   \n",
       "...                               ...   \n",
       "1991  Who became a photographer last?   \n",
       "1992        Who became a nurse first?   \n",
       "1993         Who became a nurse last?   \n",
       "1994        Who became a nurse first?   \n",
       "1995         Who became a nurse last?   \n",
       "\n",
       "                                            answers  \n",
       "0      {\"text\": [\"Katherine\"], \"answer_start\": [0]}  \n",
       "1        {\"text\": [\"Alfred\"], \"answer_start\": [37]}  \n",
       "2     {\"text\": [\"Katherine\"], \"answer_start\": [33]}  \n",
       "3         {\"text\": [\"Alfred\"], \"answer_start\": [0]}  \n",
       "4         {\"text\": [\"Donald\"], \"answer_start\": [0]}  \n",
       "...                                             ...  \n",
       "1991         {\"text\": [\"Tom\"], \"answer_start\": [0]}  \n",
       "1992       {\"text\": [\"Wendy\"], \"answer_start\": [0]}  \n",
       "1993      {\"text\": [\"James\"], \"answer_start\": [28]}  \n",
       "1994      {\"text\": [\"Wendy\"], \"answer_start\": [27]}  \n",
       "1995       {\"text\": [\"James\"], \"answer_start\": [0]}  \n",
       "\n",
       "[1996 rows x 3 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"before_after\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is not {a:prof}. {first_name2} is.',\n",
    "            '{first_name2} is {a:prof}. {first_name} is not.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is not {a:prof}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    ))\n",
    "name = 'Negation in context, may or may not be in question'\n",
    "# test = MFT(**t, expect=expect_squad, capability='Negation', name=name, description='' )\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Carl is not an author. Wendy is.</td>\n",
       "      <td>Who is an author?</td>\n",
       "      <td>{\"text\": [\"Wendy\"], \"answer_start\": [23]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carl is not an author. Wendy is.</td>\n",
       "      <td>Who is not an author?</td>\n",
       "      <td>{\"text\": [\"Carl\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wendy is an author. Carl is not.</td>\n",
       "      <td>Who is an author?</td>\n",
       "      <td>{\"text\": [\"Wendy\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wendy is an author. Carl is not.</td>\n",
       "      <td>Who is not an author?</td>\n",
       "      <td>{\"text\": [\"Carl\"], \"answer_start\": [20]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Richard is not an assistant. Nick is.</td>\n",
       "      <td>Who is an assistant?</td>\n",
       "      <td>{\"text\": [\"Nick\"], \"answer_start\": [29]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>Ruth is an artist. Kevin is not.</td>\n",
       "      <td>Who is not an artist?</td>\n",
       "      <td>{\"text\": [\"Kevin\"], \"answer_start\": [19]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>Louis is not an entrepreneur. Richard is.</td>\n",
       "      <td>Who is an entrepreneur?</td>\n",
       "      <td>{\"text\": [\"Richard\"], \"answer_start\": [30]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>Louis is not an entrepreneur. Richard is.</td>\n",
       "      <td>Who is not an entrepreneur?</td>\n",
       "      <td>{\"text\": [\"Louis\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>Richard is an entrepreneur. Louis is not.</td>\n",
       "      <td>Who is an entrepreneur?</td>\n",
       "      <td>{\"text\": [\"Richard\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>Richard is an entrepreneur. Louis is not.</td>\n",
       "      <td>Who is not an entrepreneur?</td>\n",
       "      <td>{\"text\": [\"Louis\"], \"answer_start\": [28]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1980 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        context                     question  \\\n",
       "0              Carl is not an author. Wendy is.            Who is an author?   \n",
       "1              Carl is not an author. Wendy is.        Who is not an author?   \n",
       "2              Wendy is an author. Carl is not.            Who is an author?   \n",
       "3              Wendy is an author. Carl is not.        Who is not an author?   \n",
       "4         Richard is not an assistant. Nick is.         Who is an assistant?   \n",
       "...                                         ...                          ...   \n",
       "1975           Ruth is an artist. Kevin is not.        Who is not an artist?   \n",
       "1976  Louis is not an entrepreneur. Richard is.      Who is an entrepreneur?   \n",
       "1977  Louis is not an entrepreneur. Richard is.  Who is not an entrepreneur?   \n",
       "1978  Richard is an entrepreneur. Louis is not.      Who is an entrepreneur?   \n",
       "1979  Richard is an entrepreneur. Louis is not.  Who is not an entrepreneur?   \n",
       "\n",
       "                                          answers  \n",
       "0       {\"text\": [\"Wendy\"], \"answer_start\": [23]}  \n",
       "1         {\"text\": [\"Carl\"], \"answer_start\": [0]}  \n",
       "2        {\"text\": [\"Wendy\"], \"answer_start\": [0]}  \n",
       "3        {\"text\": [\"Carl\"], \"answer_start\": [20]}  \n",
       "4        {\"text\": [\"Nick\"], \"answer_start\": [29]}  \n",
       "...                                           ...  \n",
       "1975    {\"text\": [\"Kevin\"], \"answer_start\": [19]}  \n",
       "1976  {\"text\": [\"Richard\"], \"answer_start\": [30]}  \n",
       "1977     {\"text\": [\"Louis\"], \"answer_start\": [0]}  \n",
       "1978   {\"text\": [\"Richard\"], \"answer_start\": [0]}  \n",
       "1979    {\"text\": [\"Louis\"], \"answer_start\": [28]}  \n",
       "\n",
       "[1980 rows x 3 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"negation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not in context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} is {a:prof}. {first_name2} is {a:prof2}.',\n",
    "            '{first_name2} is {a:prof2}. {first_name} is {a:prof}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is not {a:prof}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {a:prof2}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is not {a:prof2}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    ))\n",
    "name = 'Negation in question only.'\n",
    "# test = MFT(**t, expect=expect_squad, capability='Negation', name=name, description='' )\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nick is an agent. Roy is an economist.</td>\n",
       "      <td>Who is an agent?</td>\n",
       "      <td>{\"text\": [\"Nick\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nick is an agent. Roy is an economist.</td>\n",
       "      <td>Who is not an agent?</td>\n",
       "      <td>{\"text\": [\"Roy\"], \"answer_start\": [18]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nick is an agent. Roy is an economist.</td>\n",
       "      <td>Who is an economist?</td>\n",
       "      <td>{\"text\": [\"Roy\"], \"answer_start\": [18]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nick is an agent. Roy is an economist.</td>\n",
       "      <td>Who is not an economist?</td>\n",
       "      <td>{\"text\": [\"Nick\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Roy is an economist. Nick is an agent.</td>\n",
       "      <td>Who is an agent?</td>\n",
       "      <td>{\"text\": [\"Nick\"], \"answer_start\": [21]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3867</th>\n",
       "      <td>Lisa is a journalist. Sam is an executive.</td>\n",
       "      <td>Who is not an executive?</td>\n",
       "      <td>{\"text\": [\"Lisa\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3868</th>\n",
       "      <td>Sam is an executive. Lisa is a journalist.</td>\n",
       "      <td>Who is a journalist?</td>\n",
       "      <td>{\"text\": [\"Lisa\"], \"answer_start\": [21]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3869</th>\n",
       "      <td>Sam is an executive. Lisa is a journalist.</td>\n",
       "      <td>Who is not a journalist?</td>\n",
       "      <td>{\"text\": [\"Sam\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3870</th>\n",
       "      <td>Sam is an executive. Lisa is a journalist.</td>\n",
       "      <td>Who is an executive?</td>\n",
       "      <td>{\"text\": [\"Sam\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3871</th>\n",
       "      <td>Sam is an executive. Lisa is a journalist.</td>\n",
       "      <td>Who is not an executive?</td>\n",
       "      <td>{\"text\": [\"Lisa\"], \"answer_start\": [21]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3872 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         context                  question  \\\n",
       "0         Nick is an agent. Roy is an economist.          Who is an agent?   \n",
       "1         Nick is an agent. Roy is an economist.      Who is not an agent?   \n",
       "2         Nick is an agent. Roy is an economist.      Who is an economist?   \n",
       "3         Nick is an agent. Roy is an economist.  Who is not an economist?   \n",
       "4         Roy is an economist. Nick is an agent.          Who is an agent?   \n",
       "...                                          ...                       ...   \n",
       "3867  Lisa is a journalist. Sam is an executive.  Who is not an executive?   \n",
       "3868  Sam is an executive. Lisa is a journalist.      Who is a journalist?   \n",
       "3869  Sam is an executive. Lisa is a journalist.  Who is not a journalist?   \n",
       "3870  Sam is an executive. Lisa is a journalist.      Who is an executive?   \n",
       "3871  Sam is an executive. Lisa is a journalist.  Who is not an executive?   \n",
       "\n",
       "                                       answers  \n",
       "0      {\"text\": [\"Nick\"], \"answer_start\": [0]}  \n",
       "1      {\"text\": [\"Roy\"], \"answer_start\": [18]}  \n",
       "2      {\"text\": [\"Roy\"], \"answer_start\": [18]}  \n",
       "3      {\"text\": [\"Nick\"], \"answer_start\": [0]}  \n",
       "4     {\"text\": [\"Nick\"], \"answer_start\": [21]}  \n",
       "...                                        ...  \n",
       "3867   {\"text\": [\"Lisa\"], \"answer_start\": [0]}  \n",
       "3868  {\"text\": [\"Lisa\"], \"answer_start\": [21]}  \n",
       "3869    {\"text\": [\"Sam\"], \"answer_start\": [0]}  \n",
       "3870    {\"text\": [\"Sam\"], \"answer_start\": [0]}  \n",
       "3871  {\"text\": [\"Lisa\"], \"answer_start\": [21]}  \n",
       "\n",
       "[3872 rows x 3 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"negation_question\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness spinoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "fewer_profs = ['doctor', 'nurse', 'secretary', 'CEO']\n",
    "t = editor.template(\n",
    "    [\n",
    "        ('{male} is not {a:prof}, {female} is.', 'Who is {a:prof}?', '{female}', 'woman', '{prof}'),\n",
    "        ('{female} is not {a:prof}, {male} is.', 'Who is {a:prof}?', '{male}', 'man', '{prof}'),\n",
    "    ],\n",
    "#     prof=professions + ['doctor'],\n",
    "    prof=fewer_profs,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=1000,\n",
    "    unroll=True,\n",
    "    save=True,\n",
    "    )\n",
    "data = [(d[0], d[1]) for d in t.data]\n",
    "labels = [d[2] for d in t.data]\n",
    "meta = [(d[3], d[4]) for d in t.data]\n",
    "\n",
    "# test = MFT(data, expect=expect_squad, labels=labels, meta=meta, templates=t.templates,\n",
    "#           name='M/F failure rates should be similar for different professions', capability='Fairness',\n",
    "#           description='Using negation in context.')\n",
    "# test.run(predconfs, n=100)\n",
    "\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.data = [[i] for i in data]\n",
    "t.labels = [[i] for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adam is not a nurse, Sharon is.</td>\n",
       "      <td>Who is a nurse?</td>\n",
       "      <td>{\"text\": [\"Sharon\"], \"answer_start\": [21]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sharon is not a nurse, Adam is.</td>\n",
       "      <td>Who is a nurse?</td>\n",
       "      <td>{\"text\": [\"Adam\"], \"answer_start\": [23]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paul is not a doctor, Jill is.</td>\n",
       "      <td>Who is a doctor?</td>\n",
       "      <td>{\"text\": [\"Jill\"], \"answer_start\": [22]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jill is not a doctor, Paul is.</td>\n",
       "      <td>Who is a doctor?</td>\n",
       "      <td>{\"text\": [\"Paul\"], \"answer_start\": [22]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thomas is not a CEO, Betty is.</td>\n",
       "      <td>Who is a CEO?</td>\n",
       "      <td>{\"text\": [\"Betty\"], \"answer_start\": [21]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>Martha is not a doctor, Tim is.</td>\n",
       "      <td>Who is a doctor?</td>\n",
       "      <td>{\"text\": [\"Tim\"], \"answer_start\": [24]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>Chris is not a secretary, Diane is.</td>\n",
       "      <td>Who is a secretary?</td>\n",
       "      <td>{\"text\": [\"Diane\"], \"answer_start\": [26]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>Diane is not a secretary, Chris is.</td>\n",
       "      <td>Who is a secretary?</td>\n",
       "      <td>{\"text\": [\"Chris\"], \"answer_start\": [26]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>Brian is not a CEO, Kathryn is.</td>\n",
       "      <td>Who is a CEO?</td>\n",
       "      <td>{\"text\": [\"Kathryn\"], \"answer_start\": [20]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>Kathryn is not a CEO, Brian is.</td>\n",
       "      <td>Who is a CEO?</td>\n",
       "      <td>{\"text\": [\"Brian\"], \"answer_start\": [22]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1974 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  context             question  \\\n",
       "0         Adam is not a nurse, Sharon is.      Who is a nurse?   \n",
       "1         Sharon is not a nurse, Adam is.      Who is a nurse?   \n",
       "2          Paul is not a doctor, Jill is.     Who is a doctor?   \n",
       "3          Jill is not a doctor, Paul is.     Who is a doctor?   \n",
       "4          Thomas is not a CEO, Betty is.        Who is a CEO?   \n",
       "...                                   ...                  ...   \n",
       "1969      Martha is not a doctor, Tim is.     Who is a doctor?   \n",
       "1970  Chris is not a secretary, Diane is.  Who is a secretary?   \n",
       "1971  Diane is not a secretary, Chris is.  Who is a secretary?   \n",
       "1972      Brian is not a CEO, Kathryn is.        Who is a CEO?   \n",
       "1973      Kathryn is not a CEO, Brian is.        Who is a CEO?   \n",
       "\n",
       "                                          answers  \n",
       "0      {\"text\": [\"Sharon\"], \"answer_start\": [21]}  \n",
       "1        {\"text\": [\"Adam\"], \"answer_start\": [23]}  \n",
       "2        {\"text\": [\"Jill\"], \"answer_start\": [22]}  \n",
       "3        {\"text\": [\"Paul\"], \"answer_start\": [22]}  \n",
       "4       {\"text\": [\"Betty\"], \"answer_start\": [21]}  \n",
       "...                                           ...  \n",
       "1969      {\"text\": [\"Tim\"], \"answer_start\": [24]}  \n",
       "1970    {\"text\": [\"Diane\"], \"answer_start\": [26]}  \n",
       "1971    {\"text\": [\"Chris\"], \"answer_start\": [26]}  \n",
       "1972  {\"text\": [\"Kathryn\"], \"answer_start\": [20]}  \n",
       "1973    {\"text\": [\"Brian\"], \"answer_start\": [22]}  \n",
       "\n",
       "[1974 rows x 3 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"fair\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic coref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'actress' in professions:\n",
    "    professions.remove('actress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{male} and {female} are friends. He is {a:prof1}, and she is {a:prof2}.',\n",
    "            '{female} and {male} are friends. He is {a:prof1}, and she is {a:prof2}.',\n",
    "            '{male} and {female} are friends. She is {a:prof2}, and he is {a:prof1}.',\n",
    "            '{female} and {male} are friends. She is {a:prof2}, and he is {a:prof1}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof1}?',\n",
    "                '{male}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {a:prof2}?',\n",
    "                '{female}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    ))\n",
    "name = 'Basic coref, he / she'\n",
    "# test = MFT(**t, expect=expect_squad, name=name, description='', capability='Coref')\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joe and Katie are friends. He is an assistant,...</td>\n",
       "      <td>Who is an assistant?</td>\n",
       "      <td>{\"text\": [\"Joe\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joe and Katie are friends. He is an assistant,...</td>\n",
       "      <td>Who is a reporter?</td>\n",
       "      <td>{\"text\": [\"Katie\"], \"answer_start\": [8]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Katie and Joe are friends. He is an assistant,...</td>\n",
       "      <td>Who is an assistant?</td>\n",
       "      <td>{\"text\": [\"Joe\"], \"answer_start\": [10]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Katie and Joe are friends. He is an assistant,...</td>\n",
       "      <td>Who is a reporter?</td>\n",
       "      <td>{\"text\": [\"Katie\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Joe and Katie are friends. She is a reporter, ...</td>\n",
       "      <td>Who is an assistant?</td>\n",
       "      <td>{\"text\": [\"Joe\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3915</th>\n",
       "      <td>Rose and Henry are friends. He is an architect...</td>\n",
       "      <td>Who is an intern?</td>\n",
       "      <td>{\"text\": [\"Rose\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3916</th>\n",
       "      <td>Henry and Rose are friends. She is an intern, ...</td>\n",
       "      <td>Who is an architect?</td>\n",
       "      <td>{\"text\": [\"Henry\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3917</th>\n",
       "      <td>Henry and Rose are friends. She is an intern, ...</td>\n",
       "      <td>Who is an intern?</td>\n",
       "      <td>{\"text\": [\"Rose\"], \"answer_start\": [10]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3918</th>\n",
       "      <td>Rose and Henry are friends. She is an intern, ...</td>\n",
       "      <td>Who is an architect?</td>\n",
       "      <td>{\"text\": [\"Henry\"], \"answer_start\": [9]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3919</th>\n",
       "      <td>Rose and Henry are friends. She is an intern, ...</td>\n",
       "      <td>Who is an intern?</td>\n",
       "      <td>{\"text\": [\"Rose\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3920 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                context              question  \\\n",
       "0     Joe and Katie are friends. He is an assistant,...  Who is an assistant?   \n",
       "1     Joe and Katie are friends. He is an assistant,...    Who is a reporter?   \n",
       "2     Katie and Joe are friends. He is an assistant,...  Who is an assistant?   \n",
       "3     Katie and Joe are friends. He is an assistant,...    Who is a reporter?   \n",
       "4     Joe and Katie are friends. She is a reporter, ...  Who is an assistant?   \n",
       "...                                                 ...                   ...   \n",
       "3915  Rose and Henry are friends. He is an architect...     Who is an intern?   \n",
       "3916  Henry and Rose are friends. She is an intern, ...  Who is an architect?   \n",
       "3917  Henry and Rose are friends. She is an intern, ...     Who is an intern?   \n",
       "3918  Rose and Henry are friends. She is an intern, ...  Who is an architect?   \n",
       "3919  Rose and Henry are friends. She is an intern, ...     Who is an intern?   \n",
       "\n",
       "                                       answers  \n",
       "0       {\"text\": [\"Joe\"], \"answer_start\": [0]}  \n",
       "1     {\"text\": [\"Katie\"], \"answer_start\": [8]}  \n",
       "2      {\"text\": [\"Joe\"], \"answer_start\": [10]}  \n",
       "3     {\"text\": [\"Katie\"], \"answer_start\": [0]}  \n",
       "4       {\"text\": [\"Joe\"], \"answer_start\": [0]}  \n",
       "...                                        ...  \n",
       "3915   {\"text\": [\"Rose\"], \"answer_start\": [0]}  \n",
       "3916  {\"text\": [\"Henry\"], \"answer_start\": [0]}  \n",
       "3917  {\"text\": [\"Rose\"], \"answer_start\": [10]}  \n",
       "3918  {\"text\": [\"Henry\"], \"answer_start\": [9]}  \n",
       "3919   {\"text\": [\"Rose\"], \"answer_start\": [0]}  \n",
       "\n",
       "[3920 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"basic_coref\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{male} and {female} are friends. His mom is {a:prof}.',\n",
    "            '{female} and {male} are friends. His mom is {a:prof}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Whose mom is {a:prof}?',\n",
    "                '{male}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=250,\n",
    "    ))\n",
    "t += crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{male} and {female} are friends. Her mom is {a:prof}.',\n",
    "            '{female} and {male} are friends. Her mom is {a:prof}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Whose mom is {a:prof}?',\n",
    "                '{female}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=250,\n",
    "    ))\n",
    "\n",
    "name = 'Basic coref, his / her'\n",
    "# test = MFT(**t, expect=expect_squad, name=name, description='', capability='Coref')\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albert and Ellen are friends. His mom is an at...</td>\n",
       "      <td>Whose mom is an attorney?</td>\n",
       "      <td>{\"text\": [\"Albert\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellen and Albert are friends. His mom is an at...</td>\n",
       "      <td>Whose mom is an attorney?</td>\n",
       "      <td>{\"text\": [\"Albert\"], \"answer_start\": [10]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tim and Grace are friends. His mom is an entre...</td>\n",
       "      <td>Whose mom is an entrepreneur?</td>\n",
       "      <td>{\"text\": [\"Tim\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grace and Tim are friends. His mom is an entre...</td>\n",
       "      <td>Whose mom is an entrepreneur?</td>\n",
       "      <td>{\"text\": [\"Tim\"], \"answer_start\": [10]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Steve and Amy are friends. His mom is an entre...</td>\n",
       "      <td>Whose mom is an entrepreneur?</td>\n",
       "      <td>{\"text\": [\"Steve\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Nicole and Sam are friends. Her mom is an orga...</td>\n",
       "      <td>Whose mom is an organizer?</td>\n",
       "      <td>{\"text\": [\"Nicole\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Eric and Diana are friends. Her mom is a produ...</td>\n",
       "      <td>Whose mom is a producer?</td>\n",
       "      <td>{\"text\": [\"Diana\"], \"answer_start\": [9]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Diana and Eric are friends. Her mom is a produ...</td>\n",
       "      <td>Whose mom is a producer?</td>\n",
       "      <td>{\"text\": [\"Diana\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Harold and Donna are friends. Her mom is an or...</td>\n",
       "      <td>Whose mom is an organizer?</td>\n",
       "      <td>{\"text\": [\"Donna\"], \"answer_start\": [11]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Donna and Harold are friends. Her mom is an or...</td>\n",
       "      <td>Whose mom is an organizer?</td>\n",
       "      <td>{\"text\": [\"Donna\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               context  \\\n",
       "0    Albert and Ellen are friends. His mom is an at...   \n",
       "1    Ellen and Albert are friends. His mom is an at...   \n",
       "2    Tim and Grace are friends. His mom is an entre...   \n",
       "3    Grace and Tim are friends. His mom is an entre...   \n",
       "4    Steve and Amy are friends. His mom is an entre...   \n",
       "..                                                 ...   \n",
       "995  Nicole and Sam are friends. Her mom is an orga...   \n",
       "996  Eric and Diana are friends. Her mom is a produ...   \n",
       "997  Diana and Eric are friends. Her mom is a produ...   \n",
       "998  Harold and Donna are friends. Her mom is an or...   \n",
       "999  Donna and Harold are friends. Her mom is an or...   \n",
       "\n",
       "                          question                                     answers  \n",
       "0        Whose mom is an attorney?   {\"text\": [\"Albert\"], \"answer_start\": [0]}  \n",
       "1        Whose mom is an attorney?  {\"text\": [\"Albert\"], \"answer_start\": [10]}  \n",
       "2    Whose mom is an entrepreneur?      {\"text\": [\"Tim\"], \"answer_start\": [0]}  \n",
       "3    Whose mom is an entrepreneur?     {\"text\": [\"Tim\"], \"answer_start\": [10]}  \n",
       "4    Whose mom is an entrepreneur?    {\"text\": [\"Steve\"], \"answer_start\": [0]}  \n",
       "..                             ...                                         ...  \n",
       "995     Whose mom is an organizer?   {\"text\": [\"Nicole\"], \"answer_start\": [0]}  \n",
       "996       Whose mom is a producer?    {\"text\": [\"Diana\"], \"answer_start\": [9]}  \n",
       "997       Whose mom is a producer?    {\"text\": [\"Diana\"], \"answer_start\": [0]}  \n",
       "998     Whose mom is an organizer?   {\"text\": [\"Donna\"], \"answer_start\": [11]}  \n",
       "999     Whose mom is an organizer?    {\"text\": [\"Donna\"], \"answer_start\": [0]}  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"basic_coref2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Former, latter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} and {first_name2} are friends. The former is {a:prof1}.',\n",
    "            '{first_name2} and {first_name} are friends. The latter is {a:prof1}.',\n",
    "            '{first_name} and {first_name2} are friends. The former is {a:prof1} and the latter is {a:prof2}.',\n",
    "            '{first_name2} and {first_name} are friends. The former is {a:prof2} and the latter is {a:prof1}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who is {a:prof1}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    prof=professions,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    save=True\n",
    "    ))\n",
    "name = 'Former / Latter'\n",
    "# test = MFT(**t, expect=expect_squad, name=name, description='', capability='Coref')\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grace and Suzanne are friends. The former is a...</td>\n",
       "      <td>Who is an engineer?</td>\n",
       "      <td>{\"text\": [\"Grace\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Suzanne and Grace are friends. The latter is a...</td>\n",
       "      <td>Who is an engineer?</td>\n",
       "      <td>{\"text\": [\"Grace\"], \"answer_start\": [12]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grace and Suzanne are friends. The former is a...</td>\n",
       "      <td>Who is an engineer?</td>\n",
       "      <td>{\"text\": [\"Grace\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suzanne and Grace are friends. The former is a...</td>\n",
       "      <td>Who is an engineer?</td>\n",
       "      <td>{\"text\": [\"Grace\"], \"answer_start\": [12]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sam and Benjamin are friends. The former is an...</td>\n",
       "      <td>Who is an investigator?</td>\n",
       "      <td>{\"text\": [\"Sam\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959</th>\n",
       "      <td>Deborah and Suzanne are friends. The former is...</td>\n",
       "      <td>Who is a nurse?</td>\n",
       "      <td>{\"text\": [\"Suzanne\"], \"answer_start\": [12]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>Anne and Dorothy are friends. The former is an...</td>\n",
       "      <td>Who is an assistant?</td>\n",
       "      <td>{\"text\": [\"Anne\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>Dorothy and Anne are friends. The latter is an...</td>\n",
       "      <td>Who is an assistant?</td>\n",
       "      <td>{\"text\": [\"Anne\"], \"answer_start\": [12]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>Anne and Dorothy are friends. The former is an...</td>\n",
       "      <td>Who is an assistant?</td>\n",
       "      <td>{\"text\": [\"Anne\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>Dorothy and Anne are friends. The former is an...</td>\n",
       "      <td>Who is an assistant?</td>\n",
       "      <td>{\"text\": [\"Anne\"], \"answer_start\": [12]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1964 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                context  \\\n",
       "0     Grace and Suzanne are friends. The former is a...   \n",
       "1     Suzanne and Grace are friends. The latter is a...   \n",
       "2     Grace and Suzanne are friends. The former is a...   \n",
       "3     Suzanne and Grace are friends. The former is a...   \n",
       "4     Sam and Benjamin are friends. The former is an...   \n",
       "...                                                 ...   \n",
       "1959  Deborah and Suzanne are friends. The former is...   \n",
       "1960  Anne and Dorothy are friends. The former is an...   \n",
       "1961  Dorothy and Anne are friends. The latter is an...   \n",
       "1962  Anne and Dorothy are friends. The former is an...   \n",
       "1963  Dorothy and Anne are friends. The former is an...   \n",
       "\n",
       "                     question                                      answers  \n",
       "0         Who is an engineer?     {\"text\": [\"Grace\"], \"answer_start\": [0]}  \n",
       "1         Who is an engineer?    {\"text\": [\"Grace\"], \"answer_start\": [12]}  \n",
       "2         Who is an engineer?     {\"text\": [\"Grace\"], \"answer_start\": [0]}  \n",
       "3         Who is an engineer?    {\"text\": [\"Grace\"], \"answer_start\": [12]}  \n",
       "4     Who is an investigator?       {\"text\": [\"Sam\"], \"answer_start\": [0]}  \n",
       "...                       ...                                          ...  \n",
       "1959          Who is a nurse?  {\"text\": [\"Suzanne\"], \"answer_start\": [12]}  \n",
       "1960     Who is an assistant?      {\"text\": [\"Anne\"], \"answer_start\": [0]}  \n",
       "1961     Who is an assistant?     {\"text\": [\"Anne\"], \"answer_start\": [12]}  \n",
       "1962     Who is an assistant?      {\"text\": [\"Anne\"], \"answer_start\": [0]}  \n",
       "1963     Who is an assistant?     {\"text\": [\"Anne\"], \"answer_start\": [12]}  \n",
       "\n",
       "[1964 rows x 3 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"former\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "generator raised StopIteration",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pattern\\text\\__init__.py:609\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(path, encoding, comment)\u001b[0m\n\u001b[0;32m    608\u001b[0m         \u001b[39myield\u001b[39;00m line\n\u001b[1;32m--> 609\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "\u001b[1;31mStopIteration\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpattern\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39men\u001b[39;00m\n\u001b[0;32m      3\u001b[0m pverb \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mlove\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlike\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mremember\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrecognize\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtrust\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdeserve\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39munderstand\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mblame\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdislike\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mprefer\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfollow\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mnotice\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhurt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbother\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msupport\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbelieve\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39maccept\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mattack\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m a \u001b[39m=\u001b[39m pattern\u001b[39m.\u001b[39;49men\u001b[39m.\u001b[39;49mtenses(\u001b[39m'\u001b[39;49m\u001b[39mloves\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m b \u001b[39m=\u001b[39m pattern\u001b[39m.\u001b[39men\u001b[39m.\u001b[39mtenses(\u001b[39m'\u001b[39m\u001b[39mstolen\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m      6\u001b[0m pverb \u001b[39m=\u001b[39m [(pattern\u001b[39m.\u001b[39men\u001b[39m.\u001b[39mconjugate(v, \u001b[39m*\u001b[39ma), pattern\u001b[39m.\u001b[39men\u001b[39m.\u001b[39mconjugate(v, \u001b[39m*\u001b[39mb)) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m pverb]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pattern\\text\\__init__.py:2227\u001b[0m, in \u001b[0;36mVerbs.tenses\u001b[1;34m(self, verb, parse)\u001b[0m\n\u001b[0;32m   2225\u001b[0m verb \u001b[39m=\u001b[39m verb\u001b[39m.\u001b[39mlower()\n\u001b[0;32m   2226\u001b[0m a \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[1;32m-> 2227\u001b[0m b \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlemma(verb, parse\u001b[39m=\u001b[39;49mparse)\n\u001b[0;32m   2228\u001b[0m v \u001b[39m=\u001b[39m []\n\u001b[0;32m   2229\u001b[0m \u001b[39mif\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pattern\\text\\__init__.py:2172\u001b[0m, in \u001b[0;36mVerbs.lemma\u001b[1;34m(self, verb, parse)\u001b[0m\n\u001b[0;32m   2169\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" Returns the infinitive form of the given verb, or None.\u001b[39;00m\n\u001b[0;32m   2170\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2171\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mdict\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__len__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 2172\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload()\n\u001b[0;32m   2173\u001b[0m \u001b[39mif\u001b[39;00m verb\u001b[39m.\u001b[39mlower() \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inverse:\n\u001b[0;32m   2174\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inverse[verb\u001b[39m.\u001b[39mlower()]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pattern\\text\\__init__.py:2127\u001b[0m, in \u001b[0;36mVerbs.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2124\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   2125\u001b[0m     \u001b[39m# have,,,has,,having,,,,,had,had,haven't,,,hasn't,,,,,,,hadn't,hadn't\u001b[39;00m\n\u001b[0;32m   2126\u001b[0m     \u001b[39mid\u001b[39m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format[TENSES_ID[INFINITIVE]]\n\u001b[1;32m-> 2127\u001b[0m     \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m _read(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path):\n\u001b[0;32m   2128\u001b[0m         v \u001b[39m=\u001b[39m v\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2129\u001b[0m         \u001b[39mdict\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__setitem__\u001b[39m(\u001b[39mself\u001b[39m, v[\u001b[39mid\u001b[39m], v)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: generator raised StopIteration"
     ]
    }
   ],
   "source": [
    "import pattern\n",
    "import pattern.en\n",
    "pverb = ['love', 'hate', 'like', 'remember', 'recognize', 'trust', 'deserve', 'understand', 'blame', 'dislike', 'prefer', 'follow', 'notice', 'hurt', 'bother', 'support', 'believe', 'accept', 'attack']\n",
    "a = pattern.en.tenses('loves')[0]\n",
    "b = pattern.en.tenses('stolen')[0]\n",
    "pverb = [(pattern.en.conjugate(v, *a), pattern.en.conjugate(v, *b)) for v in pverb]\n",
    "\n",
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} {v[0]} {first_name2}.',\n",
    "            '{first_name2} is {v[1]} by {first_name}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who {v[0]}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {v[1]}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    v=pverb,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    ))\n",
    "name = 'Agent / object distinction'\n",
    "# test = MFT(**t, expect=expect_squad, name=name, description='', capability='SRL')\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Martin dislikes Jean.</td>\n",
       "      <td>Who dislikes?</td>\n",
       "      <td>{\"text\": [\"Martin\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Martin dislikes Jean.</td>\n",
       "      <td>Who is disliked?</td>\n",
       "      <td>{\"text\": [\"Jean\"], \"answer_start\": [16]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jean is disliked by Martin.</td>\n",
       "      <td>Who dislikes?</td>\n",
       "      <td>{\"text\": [\"Martin\"], \"answer_start\": [20]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jean is disliked by Martin.</td>\n",
       "      <td>Who is disliked?</td>\n",
       "      <td>{\"text\": [\"Jean\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Katherine trusts Frances.</td>\n",
       "      <td>Who trusts?</td>\n",
       "      <td>{\"text\": [\"Katherine\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>Suzanne is believed by Kate.</td>\n",
       "      <td>Who is believed?</td>\n",
       "      <td>{\"text\": [\"Suzanne\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>Dan attacks Greg.</td>\n",
       "      <td>Who attacks?</td>\n",
       "      <td>{\"text\": [\"Dan\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>Dan attacks Greg.</td>\n",
       "      <td>Who is attacked?</td>\n",
       "      <td>{\"text\": [\"Greg\"], \"answer_start\": [12]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>Greg is attacked by Dan.</td>\n",
       "      <td>Who attacks?</td>\n",
       "      <td>{\"text\": [\"Dan\"], \"answer_start\": [20]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Greg is attacked by Dan.</td>\n",
       "      <td>Who is attacked?</td>\n",
       "      <td>{\"text\": [\"Greg\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1996 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           context          question  \\\n",
       "0            Martin dislikes Jean.     Who dislikes?   \n",
       "1            Martin dislikes Jean.  Who is disliked?   \n",
       "2      Jean is disliked by Martin.     Who dislikes?   \n",
       "3      Jean is disliked by Martin.  Who is disliked?   \n",
       "4        Katherine trusts Frances.       Who trusts?   \n",
       "...                            ...               ...   \n",
       "1991  Suzanne is believed by Kate.  Who is believed?   \n",
       "1992             Dan attacks Greg.      Who attacks?   \n",
       "1993             Dan attacks Greg.  Who is attacked?   \n",
       "1994      Greg is attacked by Dan.      Who attacks?   \n",
       "1995      Greg is attacked by Dan.  Who is attacked?   \n",
       "\n",
       "                                           answers  \n",
       "0        {\"text\": [\"Martin\"], \"answer_start\": [0]}  \n",
       "1         {\"text\": [\"Jean\"], \"answer_start\": [16]}  \n",
       "2       {\"text\": [\"Martin\"], \"answer_start\": [20]}  \n",
       "3          {\"text\": [\"Jean\"], \"answer_start\": [0]}  \n",
       "4     {\"text\": [\"Katherine\"], \"answer_start\": [0]}  \n",
       "...                                            ...  \n",
       "1991    {\"text\": [\"Suzanne\"], \"answer_start\": [0]}  \n",
       "1992        {\"text\": [\"Dan\"], \"answer_start\": [0]}  \n",
       "1993      {\"text\": [\"Greg\"], \"answer_start\": [12]}  \n",
       "1994       {\"text\": [\"Dan\"], \"answer_start\": [20]}  \n",
       "1995       {\"text\": [\"Greg\"], \"answer_start\": [0]}  \n",
       "\n",
       "[1996 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = crossproduct(editor.template(\n",
    "    {\n",
    "        'contexts': [\n",
    "            '{first_name} {v[0]} {first_name2}. {first_name2} {v[0]} {first_name3}.',\n",
    "            '{first_name} {v[0]} {first_name2}. {first_name3} is {v[1]} by {first_name2}.',\n",
    "            '{first_name2} is {v[1]} by {first_name}. {first_name2} {v[0]} {first_name3}.',\n",
    "            '{first_name2} is {v[1]} by {first_name}. {first_name3} is {v[1]} by {first_name2}.',\n",
    "        ],\n",
    "        'qas': [\n",
    "            (\n",
    "                'Who {v[0]} {first_name2}?',\n",
    "                '{first_name}'\n",
    "            ), \n",
    "            (\n",
    "                'Who {v[0]} {first_name3}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {v[1]} by {first_name}?',\n",
    "                '{first_name2}'\n",
    "            ), \n",
    "            (\n",
    "                'Who is {v[1]} by {first_name2}?',\n",
    "                '{first_name3}'\n",
    "            ), \n",
    "        ]\n",
    "        \n",
    "    },\n",
    "    save=True,\n",
    "    v=pverb,\n",
    "    remove_duplicates=True,\n",
    "    nsamples=500,\n",
    "    ))\n",
    "name = 'Agent / object distinction with 3 agents'\n",
    "# test = MFT(**t, expect=expect_squad, name=name, description='', capability='SRL')\n",
    "# test.run(predconfs, n=100)\n",
    "# test.summary(n=3, format_example_fn=format_squad_with_context)\n",
    "# suite.add(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Edwin a Jerry. Jerry a Catherine.</td>\n",
       "      <td>Who a Jerry?</td>\n",
       "      <td>{\"text\": [\"Edwin\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Edwin a Jerry. Jerry a Catherine.</td>\n",
       "      <td>Who a Catherine?</td>\n",
       "      <td>{\"text\": [\"Jerry\"], \"answer_start\": [8]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Edwin a Jerry. Jerry a Catherine.</td>\n",
       "      <td>Who is c by Edwin?</td>\n",
       "      <td>{\"text\": [\"Jerry\"], \"answer_start\": [8]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Edwin a Jerry. Jerry a Catherine.</td>\n",
       "      <td>Who is c by Jerry?</td>\n",
       "      <td>{\"text\": [\"Catherine\"], \"answer_start\": [23]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Edwin a Jerry. Catherine is c by Jerry.</td>\n",
       "      <td>Who a Jerry?</td>\n",
       "      <td>{\"text\": [\"Edwin\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7851</th>\n",
       "      <td>Ruth is a by Diane. Ruth h Jane.</td>\n",
       "      <td>Who is a by Ruth?</td>\n",
       "      <td>{\"text\": [\"Jane\"], \"answer_start\": [27]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7852</th>\n",
       "      <td>Ruth is a by Diane. Jane is a by Ruth.</td>\n",
       "      <td>Who h Ruth?</td>\n",
       "      <td>{\"text\": [\"Diane\"], \"answer_start\": [13]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7853</th>\n",
       "      <td>Ruth is a by Diane. Jane is a by Ruth.</td>\n",
       "      <td>Who h Jane?</td>\n",
       "      <td>{\"text\": [\"Ruth\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7854</th>\n",
       "      <td>Ruth is a by Diane. Jane is a by Ruth.</td>\n",
       "      <td>Who is a by Diane?</td>\n",
       "      <td>{\"text\": [\"Ruth\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7855</th>\n",
       "      <td>Ruth is a by Diane. Jane is a by Ruth.</td>\n",
       "      <td>Who is a by Ruth?</td>\n",
       "      <td>{\"text\": [\"Jane\"], \"answer_start\": [20]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7856 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      context            question  \\\n",
       "0           Edwin a Jerry. Jerry a Catherine.        Who a Jerry?   \n",
       "1           Edwin a Jerry. Jerry a Catherine.    Who a Catherine?   \n",
       "2           Edwin a Jerry. Jerry a Catherine.  Who is c by Edwin?   \n",
       "3           Edwin a Jerry. Jerry a Catherine.  Who is c by Jerry?   \n",
       "4     Edwin a Jerry. Catherine is c by Jerry.        Who a Jerry?   \n",
       "...                                       ...                 ...   \n",
       "7851         Ruth is a by Diane. Ruth h Jane.   Who is a by Ruth?   \n",
       "7852   Ruth is a by Diane. Jane is a by Ruth.         Who h Ruth?   \n",
       "7853   Ruth is a by Diane. Jane is a by Ruth.         Who h Jane?   \n",
       "7854   Ruth is a by Diane. Jane is a by Ruth.  Who is a by Diane?   \n",
       "7855   Ruth is a by Diane. Jane is a by Ruth.   Who is a by Ruth?   \n",
       "\n",
       "                                            answers  \n",
       "0          {\"text\": [\"Edwin\"], \"answer_start\": [0]}  \n",
       "1          {\"text\": [\"Jerry\"], \"answer_start\": [8]}  \n",
       "2          {\"text\": [\"Jerry\"], \"answer_start\": [8]}  \n",
       "3     {\"text\": [\"Catherine\"], \"answer_start\": [23]}  \n",
       "4          {\"text\": [\"Edwin\"], \"answer_start\": [0]}  \n",
       "...                                             ...  \n",
       "7851       {\"text\": [\"Jane\"], \"answer_start\": [27]}  \n",
       "7852      {\"text\": [\"Diane\"], \"answer_start\": [13]}  \n",
       "7853        {\"text\": [\"Ruth\"], \"answer_start\": [0]}  \n",
       "7854        {\"text\": [\"Ruth\"], \"answer_start\": [0]}  \n",
       "7855       {\"text\": [\"Jane\"], \"answer_start\": [20]}  \n",
       "\n",
       "[7856 rows x 3 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_fmt(t, \"agent2\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "path = 'new_data' \n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "del li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Edwin a Jerry. Jerry a Catherine.</td>\n",
       "      <td>Who a Jerry?</td>\n",
       "      <td>{\"text\": [\"Edwin\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Edwin a Jerry. Jerry a Catherine.</td>\n",
       "      <td>Who a Catherine?</td>\n",
       "      <td>{\"text\": [\"Jerry\"], \"answer_start\": [8]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Edwin a Jerry. Jerry a Catherine.</td>\n",
       "      <td>Who is c by Edwin?</td>\n",
       "      <td>{\"text\": [\"Jerry\"], \"answer_start\": [8]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Edwin a Jerry. Jerry a Catherine.</td>\n",
       "      <td>Who is c by Jerry?</td>\n",
       "      <td>{\"text\": [\"Catherine\"], \"answer_start\": [23]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Edwin a Jerry. Catherine is c by Jerry.</td>\n",
       "      <td>Who a Jerry?</td>\n",
       "      <td>{\"text\": [\"Edwin\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57407</th>\n",
       "      <td>The dipole component of the magnetic field at ...</td>\n",
       "      <td>What is Neptune's dipole magnetic moment ?</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"2.2 \\\\u00d7 1017 T\\\\u00b7m3\\\"],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57408</th>\n",
       "      <td>Abu el-Haj argues that genomics and the mappin...</td>\n",
       "      <td>Hammer and others recently aimed to test what ...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"neighbouring non-Jewish populat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57409</th>\n",
       "      <td>Ancient and medieval Hindu texts identify six ...</td>\n",
       "      <td>How many pramanas are there in Hnidu philosophy?</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"six\\\"], \\\"answer_start\\\": [42]}\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57410</th>\n",
       "      <td>The Eritrean highway system is named according...</td>\n",
       "      <td>What are the three levels of road lcassificati...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"primary (P), secondary (S), and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57411</th>\n",
       "      <td>Research commissioned by Cecil King from Mark ...</td>\n",
       "      <td>What was teh number of papers in the first pri...</td>\n",
       "      <td>\"{\\\"text\\\": [\\\"3.5 million\\\"], \\\"answer_start\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57412 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 context  \\\n",
       "0                      Edwin a Jerry. Jerry a Catherine.   \n",
       "1                      Edwin a Jerry. Jerry a Catherine.   \n",
       "2                      Edwin a Jerry. Jerry a Catherine.   \n",
       "3                      Edwin a Jerry. Jerry a Catherine.   \n",
       "4                Edwin a Jerry. Catherine is c by Jerry.   \n",
       "...                                                  ...   \n",
       "57407  The dipole component of the magnetic field at ...   \n",
       "57408  Abu el-Haj argues that genomics and the mappin...   \n",
       "57409  Ancient and medieval Hindu texts identify six ...   \n",
       "57410  The Eritrean highway system is named according...   \n",
       "57411  Research commissioned by Cecil King from Mark ...   \n",
       "\n",
       "                                                question  \\\n",
       "0                                           Who a Jerry?   \n",
       "1                                       Who a Catherine?   \n",
       "2                                     Who is c by Edwin?   \n",
       "3                                     Who is c by Jerry?   \n",
       "4                                           Who a Jerry?   \n",
       "...                                                  ...   \n",
       "57407         What is Neptune's dipole magnetic moment ?   \n",
       "57408  Hammer and others recently aimed to test what ...   \n",
       "57409   How many pramanas are there in Hnidu philosophy?   \n",
       "57410  What are the three levels of road lcassificati...   \n",
       "57411  What was teh number of papers in the first pri...   \n",
       "\n",
       "                                                 answers  \n",
       "0               {\"text\": [\"Edwin\"], \"answer_start\": [0]}  \n",
       "1               {\"text\": [\"Jerry\"], \"answer_start\": [8]}  \n",
       "2               {\"text\": [\"Jerry\"], \"answer_start\": [8]}  \n",
       "3          {\"text\": [\"Catherine\"], \"answer_start\": [23]}  \n",
       "4               {\"text\": [\"Edwin\"], \"answer_start\": [0]}  \n",
       "...                                                  ...  \n",
       "57407  \"{\\\"text\\\": [\\\"2.2 \\\\u00d7 1017 T\\\\u00b7m3\\\"],...  \n",
       "57408  \"{\\\"text\\\": [\\\"neighbouring non-Jewish populat...  \n",
       "57409    \"{\\\"text\\\": [\\\"six\\\"], \\\"answer_start\\\": [42]}\"  \n",
       "57410  \"{\\\"text\\\": [\\\"primary (P), secondary (S), and...  \n",
       "57411  \"{\\\"text\\\": [\\\"3.5 million\\\"], \\\"answer_start\\...  \n",
       "\n",
       "[57412 rows x 3 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['primary (P), secondary (S), and tertiary (T)'],\n",
       " 'answer_start': [115]}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(json.loads(frame.iloc[57410].answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.to_csv('checklist_train.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([\n",
    "    df_train[['context','question','answers']],\n",
    "    frame]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The university owns several centers around the...</td>\n",
       "      <td>At which location is the London Center operate...</td>\n",
       "      <td>{\"text\": [\"1 Suffolk Street in Trafalgar Squar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caroline is more offensive than Ashley.</td>\n",
       "      <td>Who is less defensive?</td>\n",
       "      <td>{\"text\": [\"Caroline\"], \"answer_start\": [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alexandra is r by Dan. Alexandra p Jerry.</td>\n",
       "      <td>Who is r by Alexandra?</td>\n",
       "      <td>{\"text\": [\"Jerry\"], \"answer_start\": [35]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kathryn has a lizard and a minivan.</td>\n",
       "      <td>What vehicle does Kathryn have?</td>\n",
       "      <td>{\"text\": [\"minivan\"], \"answer_start\": [27]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The song was released as a digital download on...</td>\n",
       "      <td>The release of Writing's on the Wall caused wh...</td>\n",
       "      <td>{\"text\": [\"Shirley Bassey\"], \"answer_start\": [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145006</th>\n",
       "      <td>Beyoncé's music is generally R&amp;B, but she also...</td>\n",
       "      <td>What language does she mainly sing?</td>\n",
       "      <td>{\"text\": [\"English\"], \"answer_start\": [267]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145007</th>\n",
       "      <td>BYU alumni in academia include former Dean of ...</td>\n",
       "      <td>What is former alumnus Paul D. Boyer known for...</td>\n",
       "      <td>{\"text\": [\"Nobel Prize winner\"], \"answer_start...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145008</th>\n",
       "      <td>Marshall Field &amp; Company originated in 1852. I...</td>\n",
       "      <td>In what year was Marshall Field and company es...</td>\n",
       "      <td>{\"text\": [\"1852\"], \"answer_start\": [39]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145009</th>\n",
       "      <td>Until 1998, the network carried a variety of A...</td>\n",
       "      <td>In what year did the network end American prog...</td>\n",
       "      <td>{\"text\": [\"1998\"], \"answer_start\": [6]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145010</th>\n",
       "      <td>On 1 February 1908, the king Dom Carlos I of P...</td>\n",
       "      <td>On what day was King Manuel II overthrown?</td>\n",
       "      <td>{\"text\": [\"5 October 1910\"], \"answer_start\": [...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145011 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  context  \\\n",
       "0       The university owns several centers around the...   \n",
       "1                 Caroline is more offensive than Ashley.   \n",
       "2               Alexandra is r by Dan. Alexandra p Jerry.   \n",
       "3                     Kathryn has a lizard and a minivan.   \n",
       "4       The song was released as a digital download on...   \n",
       "...                                                   ...   \n",
       "145006  Beyoncé's music is generally R&B, but she also...   \n",
       "145007  BYU alumni in academia include former Dean of ...   \n",
       "145008  Marshall Field & Company originated in 1852. I...   \n",
       "145009  Until 1998, the network carried a variety of A...   \n",
       "145010  On 1 February 1908, the king Dom Carlos I of P...   \n",
       "\n",
       "                                                 question  \\\n",
       "0       At which location is the London Center operate...   \n",
       "1                                  Who is less defensive?   \n",
       "2                                  Who is r by Alexandra?   \n",
       "3                         What vehicle does Kathryn have?   \n",
       "4       The release of Writing's on the Wall caused wh...   \n",
       "...                                                   ...   \n",
       "145006                What language does she mainly sing?   \n",
       "145007  What is former alumnus Paul D. Boyer known for...   \n",
       "145008  In what year was Marshall Field and company es...   \n",
       "145009  In what year did the network end American prog...   \n",
       "145010         On what day was King Manuel II overthrown?   \n",
       "\n",
       "                                                  answers  \n",
       "0       {\"text\": [\"1 Suffolk Street in Trafalgar Squar...  \n",
       "1             {\"text\": [\"Caroline\"], \"answer_start\": [0]}  \n",
       "2               {\"text\": [\"Jerry\"], \"answer_start\": [35]}  \n",
       "3             {\"text\": [\"minivan\"], \"answer_start\": [27]}  \n",
       "4       {\"text\": [\"Shirley Bassey\"], \"answer_start\": [...  \n",
       "...                                                   ...  \n",
       "145006       {\"text\": [\"English\"], \"answer_start\": [267]}  \n",
       "145007  {\"text\": [\"Nobel Prize winner\"], \"answer_start...  \n",
       "145008           {\"text\": [\"1852\"], \"answer_start\": [39]}  \n",
       "145009            {\"text\": [\"1998\"], \"answer_start\": [6]}  \n",
       "145010  {\"text\": [\"5 October 1910\"], \"answer_start\": [...  \n",
       "\n",
       "[145011 rows x 3 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## shuffle\n",
    "combined.iloc[np.random.permutation(len(combined))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_csv('combined_train.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
